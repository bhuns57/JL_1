{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d1664d-7240-4713-a26f-0026da29fb30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **This sbs array_dict with pickle v1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40277d-0c4e-4cb1-a3dc-e40f6bb25b12",
   "metadata": {},
   "source": [
    "# **00_setup.py** | *Refences & Imports, def_fnctna, glossary, config flags*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60ae91-135a-401c-b026-8aee7bc28167",
   "metadata": {},
   "source": [
    "## Refences & Help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbc1f1-68ff-45d7-9ecd-3a0cfa7c0e1b",
   "metadata": {},
   "source": [
    "**Modular Workbook for Array Dictionary Implementation**\n",
    "1. ***Help setting up the structure of a array_dict system and workbook***\n",
    "2. *https://copilot.microsoft.com/shares/pages/3HV5tomNJNNZi9VReAwN9*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731985b7-e1e2-4df5-8500-b0f9fc11a7c0",
   "metadata": {},
   "source": [
    "**Cross-Platform File Path Handling in Python**\n",
    "1. ***solving problems opening files in window, WWSL  and python***\n",
    "2. *https://copilot.microsoft.com/shares/pages/txcgXXLkjC8zGKTwGiCd1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22032b-7d0e-437a-b0c9-5fa37e305dfa",
   "metadata": {},
   "source": [
    "**Using Pathlib to Build File Paths in Python**\n",
    "1. ***Creatung paths in wsl is tricky using \"\"\"Pathlib\"\"\"to Build File Paths helps***\n",
    "2. *https://copilot.microsoft.com/shares/pages/SmGr7Zt8ZDNHvbidFGVZy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443aa0b-6386-4f7b-92cc-9594a6677e74",
   "metadata": {},
   "source": [
    "**WSL-Compatible File Path Handling in Python**\n",
    "1. ***variable to represent a file path in WSL***\n",
    "2. *https://copilot.microsoft.com/shares/pages/bdtSWCe2bNJPvKZSrvDXo*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ef4ff-ea59-4334-8d0e-d6f6112c5ae8",
   "metadata": {},
   "source": [
    "**Python Pickle Module Guide**\n",
    "1. ***explaination of Pickel reading and writing***\n",
    "2. *https://copilot.microsoft.com/shares/pages/qMbW8PsnCpjM1MW2EGH1z*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de248c68-8340-4da1-8061-bb7db60cd6bf",
   "metadata": {},
   "source": [
    "**Modular Batch Save/Load Utility for array_dict**\n",
    "1. ***loading many objects to pickle***\n",
    "2. *https://copilot.microsoft.com/shares/pages/TRT16QCyupBTnq8JwMuSU*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49860de7-9186-4f76-bb84-2255f21267ad",
   "metadata": {},
   "source": [
    "**Modular Pickle Utility Design**\n",
    "1. ***def functions to read and save Pickel***\n",
    "2. *https://copilot.microsoft.com/shares/pages/aeBducMjy6ZCcBzYBUW3h*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1074f-0d6c-45ef-9340-6ca9dd861d70",
   "metadata": {},
   "source": [
    "**Understanding Python Raw Strings**\n",
    "1. ***r\"\" is a an operater that instructs how to read the str it doew not change the str r\"xl_ada.csv\" and \"xl_ada.csv\" are identical once createdâ€”because there are no backslashes to escape.***\n",
    "2. *Understanding Python Raw Strings*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a8f7c-51d6-4a82-be41-58880589520b",
   "metadata": {},
   "source": [
    "**CSV Editing and Saving Workflow**\n",
    "1. ***This loads the dat_col dict for .csv file and then after editing replace the updated version into same file***\n",
    "2. *https://copilot.microsoft.com/shares/pages/QabFDtDG8Utc8EFMgzzyz*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4dbdf-cf46-4cd3-b173-cfb9728efa7b",
   "metadata": {},
   "source": [
    "**Ordered Dictionary with 'dvt' First in Python**\n",
    "1. ***This reads a 2D array with headers from .csv file and makes a std dat_col_dict like [ad_sn]***\n",
    "2. *https://copilot.microsoft.com/shares/pages/3iojVoSLAcCggGcWtxUmM*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eccb42-1e40-458c-a9fa-75c29b27a41e",
   "metadata": {},
   "source": [
    "**Optimizing Data Types for Memory Efficiency**\n",
    "1. ***This should be used before I start expanding***\n",
    "2. *https://copilot.microsoft.com/shares/pages/wGUNBVFLcxarPtGE1mwnP*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a0b36-69be-464f-ab8d-b878382ca3db",
   "metadata": {},
   "source": [
    "**Using try: on the index col**\n",
    "1. ***Try: ia valuable tool used with index method of panda***\n",
    "2. *https://copilot.microsoft.com/shares/pages/iqre2v246hhjkauLu1CGG*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb39e27-73aa-43d3-a069-7a461d20eb00",
   "metadata": {},
   "source": [
    "## Imports,glossary, Def_function_utilities, config flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c6544-b1b6-4e9f-a6d4-a545c7d470ec",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b69568-0542-40cb-90b9-cefdd5d0b3a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO =  \n",
      "base_path =  /home/bhuns\n",
      "REPO\\data =  \\data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "base_path = os.path.expanduser(\"~\")  # Gets /home/bhuns in WSL all measured from here\n",
    "REPO = \"\"\n",
    "#data = \" \\\" + \"_data\"\n",
    "print(\"REPO = \",REPO)\n",
    "print(\"base_path = \",base_path)\n",
    "print(\"REPO\\data = \",REPO + \"\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e1d9b-a410-4bda-a55d-325457688c9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2ebaa-65a4-4a3d-971c-78784a61e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:bnm is abrev for base name [common name for a type of data]\n",
    "# bnm for  array_dict is \"ad\"          \n",
    "# bnm for  array_dict_serial number is \"ad_sn\" \n",
    "# bnm for attributes is att         # attributes\n",
    "# bnh for ad \"Lablel lookup table\"   is  \"ad_sn_ad_lbl\"     # \n",
    "# csv_pathway  is in  REPO               #bu with \"git\"\n",
    "# pkl files are in REPO/data           # not bu with \"git\"\n",
    "# csv_pathway = \"bnm.csv\"            # csv versions are in data folder to use git and allow normal version free git bu\n",
    "# pkl_pathway = r\"data/bnm.pkl\"      # pkl versions are in REPO/data to avoid git and allow bu\n",
    "# list of  bnm add new as arise  USE WITH READERS AND saveS TO FILES==================\n",
    "#bnm list in 01 [List of bnm [base_names] for arrays that need to be imported and formatted]----------------------------------------------\n",
    "#bnm =  \"ad_sn\"                        # array_sn_dict\n",
    "#bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "#bnm =  \"at_sn_\"                        # attrbts_sn_x_array_dict_sn\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#adsn = the temp \"array_dict_sn\"  that is being worked on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64eb941-dab3-4119-bc71-61c77e1bdbf5",
   "metadata": {},
   "source": [
    "### Def_function_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5276f6a-6d4f-4c1b-9fd2-8b90df23dcbc",
   "metadata": {},
   "source": [
    "#### csv  array load/save "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70acfd2-42c7-4d1a-ad9e-5488d9f6eace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. Full Round trip def function\n",
    "2. for csv storage\n",
    "3. from a **\"bnm\"** [Basic data class NaMe]\n",
    "4. and a **adsn** [Array Dict Serial Number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390aceb1-30c8-4ad1-b5fc-76b8127165c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_dict(bnm):\n",
    "    \"\"\"\n",
    "    Load CSV into DataFrame and convert to ordered dict with 'dvt' first.\n",
    "    Sets 'dvt' as string index for direct access.\n",
    "    \"\"\"\n",
    "    path_csv = Path(f\"{bnm}.csv\")\n",
    "    df = pd.read_csv(path_csv)\n",
    "\n",
    "    # Ensure 'dvt' is string before setting index\n",
    "    df['dvt'] = df['dvt'].astype(str)\n",
    "    df.set_index('dvt', inplace=True)\n",
    "\n",
    "    # Build ordered dictionary with 'dvt' as first key\n",
    "    col_dict = OrderedDict()\n",
    "    col_dict['dvt'] = df.index.tolist()\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_dict[col] = df[col].tolist()\n",
    "\n",
    "    return df, col_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37894e6-78ed-4d66-b336-4d8ce1826783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Dictionary to csv in REPO\\\n",
    "# Note it converts to df and saves!!!!!!!\n",
    "def save_csv(bnm, col_dict):\n",
    "    \"\"\"\n",
    "    Reconstruct DataFrame from edited dictionary and overwrite original CSV.\n",
    "    Assumes 'dvt' is present as the first key in col_dict.\n",
    "    \"\"\"\n",
    "    # Rebuild DataFrame from dictionary\n",
    "    df_out = pd.DataFrame(col_dict)\n",
    "\n",
    "    # Ensure column order starts with 'dvt'\n",
    "    cols = ['dvt'] + [col for col in df_out.columns if col != 'dvt']\n",
    "    df_out = df_out[cols]\n",
    "\n",
    "    # Write back to original file\n",
    "    path_csv = f\"{bnm}.csv\"\n",
    "    df_out.to_csv(path_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c597b02-9d97-4fbb-abca-14f99ea1113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a value in a adsn\n",
    "def set_col_value(col_dict, dvt_key, col_name, value):\n",
    "    try:\n",
    "        idx = col_dict['dvt'].index(str(dvt_key))\n",
    "        col_dict[col_name][idx] = value\n",
    "        print(idx)\n",
    "    except ValueError:\n",
    "        print(f\"dvt {dvt_key} not found.\")\n",
    "    except KeyError:\n",
    "        print(f\"Column {col_name} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29828231-f14e-4087-8f95-9819989cbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load array from f\"{bnm}.csv\" in REPO\n",
    "bnm =\"ad_sn\"\n",
    "df, col_dict = load_csv_to_dict(bnm)  # Load original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e2fb3ec-55f7-4633-940a-af2b1a99b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Set a value in dct\n",
    "col_dict = col_dict\n",
    "dvt_key = 45863\n",
    "col_name = \"s002\"\n",
    "value = 12\n",
    "set_col_value(col_dict, dvt_key, col_name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b1b3b8-ac4f-4c31-ab24-95ac6a0c2ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dvt', ['45860', '45861', '45862', '45863', '45864', '45865']),\n",
       "             ('s000', [nan, nan, nan, nan, nan, nan]),\n",
       "             ('s001', [nan, nan, nan, nan, nan, nan]),\n",
       "             ('s002', [nan, nan, nan, 12, nan, nan]),\n",
       "             ('s003', [nan, nan, nan, nan, nan, nan]),\n",
       "             ('s004', [nan, nan, nan, nan, nan, nan])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict       # Access row by dvt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f37dfab5-44a8-4d1a-8b02-f6d6c694989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, 12, nan, nan]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict['s002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cd9c49d-3021-49a2-b922-9a5e8f9bf0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict['s002'][3]# Still accessible by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abbc26-5cf1-4e0a-bc3b-ef5d238df834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b05a48-70fd-4c2c-a941-ca579063040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... perform edits to col_dict ...\n",
    "load_edit_save_csv(bnm, col_dict)     # Save back to same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fdc42-1c06-4c7a-9a40-c7a34b62432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc0eb9-edc5-4791-8b62-e87f7f7cd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edits to adsn ...\n",
    "save_csv(bnm, adsn)     # Save back to same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db3281-7da0-4bb6-b631-0904a62f5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm =\"adsn\"\n",
    "df, adsn =load_csv_to_dict(bnm)\n",
    "print(\"df & are temp names  and need to re named realt\")\n",
    "df\n",
    "#adsn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998dfc5-f415-4c86-8c28-9502e5d8bba8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### pkl load/save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0d188-6af9-4fd2-9f26-da39f31d0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl load/save\n",
    "def load_edit_save_pkl(bnm, array_dict):\n",
    "    \"\"\"\n",
    "    Load Pickle file, apply edits to array_dict, and overwrite original file.\n",
    "    Assumes file is stored in REPO/data/{bnm}.pkl\n",
    "    \"\"\"\n",
    "    path_pkl = Path(\"REPO/data\") / f\"{bnm}.pkl\"\n",
    "\n",
    "    # Save updated dictionary back to Pickle\n",
    "    with open(path_pkl, 'wb') as f:\n",
    "        pickle.dump(array_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f386168-f659-46a1-894a-ad7ba9b1978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original Pickle\n",
    "with open(\"REPO/data/my_data.pkl\", 'rb') as f:\n",
    "    array_dict = pickle.load(f)\n",
    "\n",
    "# ... perform edits to array_dict ...\n",
    "\n",
    "# Save back to same Pickle file\n",
    "load_edit_save_pkl(\"my_data\", array_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfc663-e18e-44d8-a4cc-09b87d0d7527",
   "metadata": {},
   "source": [
    "# end ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec689e9-a13a-4a6c-9cc8-cff632f897f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "64a74b2c-2e07-461a-86b8-9376c92d55e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### load from pkl from a \"\"\"bnm\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "598bd925-31cb-41c2-81a2-5e6ccb21a46f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "def load_pickle(bmn):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    str(path_pkl)                           # change to string\n",
    "    print(path_pkl)\n",
    "    path = Path(path_pkl)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81b9e2f0-0540-4670-938f-bf5aded2ac0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Call to  # def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "bnm =\"adsn\"\n",
    "load_pickle(bnm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456f667-90c8-40c0-8c73-7e9494927fad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Save to pkl from a \"\"\"bnm\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "26ab16a5-bd35-45ed-984d-763041394362",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "def save_pkl(bnm):\n",
    "#    fl_nm(bnm)\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    str(path_pkl)                           # change to string\n",
    "    print(\"wsl folder: \",path_pkl)\n",
    "    save_pickle(bnm, path_pkl)\n",
    "    print(f\"Saving to: {path_pkl.resolve()}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ed049-62a6-4616-831a-841bcbed59fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Call to  # def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "bnm =\"ad_sn\"\n",
    "save_pkl(bnm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dabb8c9b-58cc-40fc-9a7e-c0180918756a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "path_pkl = r\"data\\ \" + bnm + \".pkl\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b7e40e3-d868-4c07-83c0-8774aa19b743",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "  path_pkl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92b6c612-2890-4fa3-9fc7-2ac284d52150",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Def_function_utilities\n",
    "def fl_nm_csv(bnm):       # calc pathway for csv files from base name bnm -- can use function directly in file readers\n",
    "    fl_nm_csv = bnm + \".csv\"\n",
    "    return fl_nm_csv\n",
    "def fl_nm(bnm):           # calc pathway for pkl files from base name bnm -- can use function directly in file readers\n",
    "    fl_nm = bnm + \".pkl\"\n",
    "    return fl_nm\n",
    "\n",
    "# ---------------------------- pathway calc ----------------------------------------------------\n",
    "def pthwy_csv(bnm):       # calc pathway for csv files from base name bnm -- can use function directly in file readers\n",
    "    pthwy_csv = bnm + \".csv\"\n",
    "    return pthwy_csv\n",
    "def pthwy_pkl(bnm):           # calc pathway for pkl files from base name bnm -- can use function directly in file readers\n",
    "    pthwy_pkl =  r\"data/\" + bnm + \".pkl\"\n",
    "    return pthwy_pkl\n",
    "\n",
    "# example -------------------------------------------------------------------------------------------------------------\n",
    "#bnm = \"ad_sn\"\n",
    "#pthwy_csv(bnm)\n",
    "# answer  'data/ad_sn.csv'  \n",
    "# pd.read_csv(pthwy_csv(bnm))\n",
    "\n",
    "#------------------ðŸ§± Basic Pickle Save/Load Utility------------------------------------\n",
    "def save_pickle(obj, path):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(\"loaded pkl = \",path)\n",
    "def load_pickle(path):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "#------------------ðŸ§± Basic csv Save/Load Utility------------------------------------\n",
    "# dict --------------------------------------------------------------------------\n",
    "def save_csv(data, path):\n",
    "    \"\"\"save list of dicts to CSV.\"\"\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        save = csv.Dictsave(f, fieldnames=data[0].keys())\n",
    "        save.saveheader()\n",
    "        save.saverows(data)\n",
    "def read_csv(path):\n",
    "    \"\"\"Read CSV into list of dicts.\"\"\"\n",
    "    with open(path, 'r', newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "# 2D array -----------------------------------------------------------------\n",
    "def save_2d_csv(array2d, path):\n",
    "    \"\"\"save 2D array (list of lists) to CSV.\"\"\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        save = csv.save(f)\n",
    "        save.saverows(array2d)\n",
    "def read_2d_csv(path):\n",
    "    \"\"\"Read CSV into 2D array (list of lists).\"\"\"\n",
    "    with open(path, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0309b-23a9-4d4a-8100-40b58ba4cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a472e1f-7a53-4e97-b6a7-5e46f4cc8903",
   "metadata": {},
   "source": [
    "# **01_array_loader.py** |  *Load data arrays from (csv and/or pkl files) format them into the required system data structures ie ***array_dict*** !*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac366f1-3487-457c-9281-8dae8e15c1ef",
   "metadata": {},
   "source": [
    "## List of bnm [base_names] for arrays that need to be imported and formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69dc314-48bf-444b-8bf2-2d74605940bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of bnm [base_names] for arrays that need to be imported and formatted\n",
    "#bnm =  \"ad_sn\"                        # array_sn_dict \n",
    "#bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "#bnm =  \"at_sn_\"                       # attrbts_sn_x_array_dict_sn\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#bnm =  \"ad_sn\"                        # array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8465d-c758-4ff1-b355-31a3c0acbb3d",
   "metadata": {},
   "source": [
    "## Import bnm [base_name]  to arrays then format to data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d430fd-d84a-4053-b115-f8365e6f86ca",
   "metadata": {},
   "source": [
    "### 0. Process steps & def definition & examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a3156-81f9-4480-86b3-f7f04b30f1bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Diagnostic only for path calcs atored in RAW change to CODE mode to test\n",
    "bnm = \"ad_sn\"\n",
    "pthwy_csv(bnm)                      # calc pathway for csv files from base name bnm -- can use function directly in file reader\n",
    "pthwy(bnm)                       # calc pathway for pkl files from base name bnm -- can use function directly in file reader\n",
    "print(\" bnm & csv & pkl pathway for verification\")   # print verification\n",
    "print(\" bnm =\",bnm,\"\\n\",\"pthwy_csv =\",pthwy_csv(bnm),\"\\n\",\"pthwy =\",pthwy(bnm))              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df5cb0-b880-4bda-8871-f65a1ddfdbd4",
   "metadata": {},
   "source": [
    "#### 2 import from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb391b-166e-4103-a153-5f6c45bac642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bnm and run\n",
    "bnm = \"ad_sn\"\n",
    "df = pd.read_csv(pthwy_csv(bnm))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f700b90-3a5b-4e57-84af-6212ecf4edbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f156f964-5e93-4785-8a33-cb7acef471f0",
   "metadata": {},
   "source": [
    "#### 2 export to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcea89e-25df-4035-b775-a358900a09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm = \"ad_sn1\"\n",
    "save_pickle(bnm,pthwy(bnm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2853d2d-2e6e-4cb8-8adc-abb96c432559",
   "metadata": {},
   "source": [
    "#### 3 format for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da68ae8-8836-4f3f-915d-79c49009d348",
   "metadata": {},
   "source": [
    "#### l calc pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6eb431-591e-483c-b648-56b8ccf03c45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Apply to bmn list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97af60d-07e4-435a-a56a-28e163dbb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pathway for bnm\n",
    "# load bmn array frome file\n",
    "# format is it for use by procecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbeed48-5c32-49f9-b592-dc3fb82581a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old ===============================================================================\n",
    "# Retreive  xl_ad_sn from .csl\n",
    "# Define the path (reset path to WSL preventing possible p errors)\n",
    "\n",
    "# since working in the ubuntu terminal use WSL rules ie r\" path \"\n",
    "base_path = os.path.expanduser(\"~\")  # Gets /home/bhuns in WSL\n",
    "csv_path = os.path.join(base_path, c)\n",
    "\n",
    "# Load with headers\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert to NumPy array (excluding headers)\n",
    "xl_ad_sn = df.to_numpy()\n",
    "#xl_ad_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f73450-e7b2-4d59-a36f-9d8c90e9524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a2685-1688-44e9-9b8c-5bf1309fbdbe",
   "metadata": {},
   "source": [
    "#### l calc pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ac38f-dd84-4bf5-bf21-cfae1ef6bd69",
   "metadata": {},
   "source": [
    "# **02_array_dict_builder.py**   |  *Transform arrays into array_dict with metadata*\n",
    "_ ***Script Update for Data Dictionary Creation** link *https://copilot.microsoft.com/shares/pages/jLLrDDP9aZqQjatwkyFfr*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb8ff7-8caf-4029-896e-5fc56b38b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and isolate the raw headers from \"xl_ad_sn_hdr,csl\"\n",
    "# Load CSV\n",
    "\n",
    "\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Inspect raw headers\n",
    "raw_headers = df.columns.tolist()\n",
    "#print(\"Raw headers:\", raw_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977397a-44e3-406b-af83-5dc193a83366",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Full Setup >> headers >> dtv_index >> array_dict\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)         # read array from \"csv_path\"\n",
    "\n",
    "# Extract headers and data\n",
    "headers = df.columns.tolist()\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "# Locate the index of the 'dtv' column\n",
    "dtv_index = headers.index('dtv')\n",
    "\n",
    "# Build array_dict\n",
    "array_dict = {}\n",
    "\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928214d4-84af-473c-a5dc-2399342ff359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ðŸ§ª Verify the construction\n",
    "\n",
    "for dtv, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DTV: {dtv}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a91b41-4db5-4c9d-aabc-806c4b3210d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Continue Building array_dict\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "array_dict = {}\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(raw_headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a6b3c-3baf-4d77-a632-e4e0f3d7502b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for dvt, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DVT: {dvt}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f33a7-965a-48dc-a670-10dfebc56ad2",
   "metadata": {},
   "source": [
    "# 03 Setting the classification of \"dat_col\"s with attribts stored in files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1be936-396b-470c-8f53-adf7c0b884fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacebebe-f719-4569-bf24-f8e13493c97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Metadata Injection Function in Python**\n",
    "_\n",
    "*https://copilot.microsoft.com/shares/pages/LpNfiWnk3ndWRko9EnfxS*\n",
    "\n",
    "_Question *I would like like to have function that would accept a \"dat_col_sn\" and and a \"attribut_sn\" and read the \"value\" in that item in the file \"attrbts_sn_x_dat_col_sn\" and set that \"attribute\" in that \"dat_col\" to that \"value\". If the class & attrbute did not exist, it would create one. Js that possible.*\n",
    "\n",
    "Absolutely, Billâ€”thatâ€™s not only possible, itâ€™s a great example of modular, operator-driven metadata injection. Youâ€™re describing a function that:\n",
    "\n",
    "Accepts a dat_col_sn (e.g. 's003') and an attribute_sn (e.g. 'a001')\n",
    "\n",
    "Looks up the value at that coordinate in a matrix file (e.g. CSV or Excel)\n",
    "\n",
    "Injects that value into the corresponding array_dict[dat_col_sn]['attributes'][attribute_sn]\n",
    "\n",
    "Creates the attribute if it doesnâ€™t exist\n",
    "\n",
    "Letâ€™s scaffold that cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00a24f-c55c-4746-b2a3-8e36c11f0c8a",
   "metadata": {},
   "source": [
    "## ðŸ§  Function: inject_attribute_from_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4da89-e8e1-4563-b31d-42123ae0a2dd",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc222d44-63c7-486b-8b31-199d3c8cb2fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. The matrix file is named \"attrbts_sn_x_dat_col_sn.csv\" ..................ok  [matrix_path]\n",
    "2. Rows = attribute_sn (e.g. 'a000', 'a001')................................ok\n",
    "3. Columns = dat_col_sn (e.g. 's000', 's001')...............................ok\n",
    "4. Youâ€™ve already built array_dict keyed by dat_col_sn.........need to load ##\n",
    "\"\\\\wsl.localhost\\Ubuntu\\home\\bhuns\\JL_1\\data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "r\"data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "\"attrbts_sn_x_dat_col_sn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5697a9a-c574-4078-9f7c-1f59ef049dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"attrbts_sn_x_dat_col_sn.csv\"\n",
    "df = read_wsl_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4ff18-12c1-4e6c-8760-a0d350f6203e",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d282555-ebff-4634-9265-f243e0e69cda",
   "metadata": {},
   "source": [
    "#### inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822aaf6-b7cb-4915-9f47-23f759e540bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "\n",
    "def inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "    # Load matrix\n",
    "    df = pd.read_csv(matrix_path, index_col=0)  # Assumes first column is attribute_sn\n",
    "\n",
    "    # Validate existence\n",
    "    if attribute_sn not in df.index:\n",
    "        raise ValueError(f\"Attribute '{attribute_sn}' not found in matrix rows.\")\n",
    "    if dat_col_sn not in df.columns:\n",
    "        raise ValueError(f\"Data column '{dat_col_sn}' not found in matrix columns.\")\n",
    "\n",
    "    # Extract value\n",
    "    value = df.at[attribute_sn, dat_col_sn]\n",
    "\n",
    "    # Inject into array_dict\n",
    "    if dat_col_sn not in array_dict:\n",
    "        raise KeyError(f\"Data column '{dat_col_sn}' not found in array_dict.\")\n",
    "\n",
    "    entry = array_dict[dat_col_sn]\n",
    "    if 'attributes' not in entry:\n",
    "        entry['attributes'] = {}\n",
    "\n",
    "    entry['attributes'][attribute_sn] = value\n",
    "\n",
    "    return value  # Optional: return for confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72aaad-bc23-4809-87f1-21e7f7b5a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ§ª Example Usage\n",
    "matrix_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/attrbts_sn_x_dat_col_sn.csv\")\n",
    "value = inject_attribute_from_matrix(array_dict, 's003', 'a001', matrix_path)\n",
    "\n",
    "print(f\"Injected value: {value}\")\n",
    "print(array_dict['s003']['attributes']['a001'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92183b-390b-4102-abe4-26f1fd701bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### ðŸ” Optional Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b019af2-6819-4602-95e7-a49ccdc9d8d6",
   "metadata": {},
   "source": [
    "Add logging or provenance tags\n",
    "\n",
    "Support batch injection for all attributes or all columns\n",
    "\n",
    "Validate types or ranges before injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f05d5-f155-4ff5-8d9e-7bc4a3b4f885",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0489f-7e62-4302-a7d9-408d6294530d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa619ee3-c338-4249-9d6c-9e391a584836",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6236d-e13d-4968-8c9a-d9c24598624e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3906b6-b0b1-4858-bd06-e6684dac4c36",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39df37d-95c7-4f9c-91bd-c1eb34ee2aad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81456798-0e17-428d-801a-171eed22c9f8",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c18f0-484b-48e4-a843-582ec26cd54c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be694f8-e508-4ad8-9e79-024d0ba2e7a1",
   "metadata": {},
   "source": [
    "# **04_gui_selector.py**  |  *Operator-driven GUI for selecting and grouping entries*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c5dfb-6795-47ed-be00-c950416bf641",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **05_storage_utils.py**  |  *Save/load using Pickle, Excel, HDF5*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d2ff6-add0-449c-932d-96d117f241e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# **0?_classification_registry.py**  |  *Define classification args, flags, and validation logic*\n",
    "_***Wrking but funct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707113e-7e27-414f-9c6e-a89fcfe1e908",
   "metadata": {},
   "source": [
    "**Classification Registry Implementation** \n",
    "_ *https://copilot.microsoft.com/shares/pages/P91viiY6QzR3Mp4WUnbFf*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375551f-c4a6-4ad2-8526-15cbe23d5b7f",
   "metadata": {},
   "source": [
    "## ðŸ§  Classification Registry Scaffold (classification_registry.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86b3d7-94b9-4fca-93c1-79cf5d508ecd",
   "metadata": {},
   "source": [
    "### Perfect, Bill. Youâ€™ve got a classification matrix scaffoldedâ€”rows as attribute_sn (e.g. a000, a001, ...) and columns as dat_col.sn (e.g. s000, s001, ...). \n",
    "1. Thatâ€™s a great foundation for a modular classification registry.\n",
    "2. Letâ€™s build a separate fileâ€”say, classification_registry.pyâ€”that can:\n",
    "3. Load and validate the matrix\n",
    "4. Apply classification logic per attribute or per column\n",
    "5. Track provenance and confidence\n",
    "6. Return structured results for embedding into array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54d75e-5f66-43af-8beb-58aba94c6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ 1. Load the Matrix\n",
    "\n",
    "def load_classification_matrix(path):\n",
    "    df = pd.read_csv(path)  # or pd.read_excel\n",
    "    df.index.name = 'attribute_sn'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce72b28-ce58-45f4-8d33-d3bdd00ebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 2. Define Classification Methods\n",
    "def threshold_classifier(row, threshold=0.5):\n",
    "    score = row.mean()\n",
    "    group = 'A' if score > threshold else 'B'\n",
    "    confidence = round(abs(score - threshold), 3)\n",
    "    return group, confidence\n",
    "\n",
    "def zscore_classifier(row):\n",
    "    z = (row - row.mean()) / row.std()\n",
    "    group = 'High' if z.mean() > 1 else 'Low'\n",
    "    confidence = round(z.std(), 3)\n",
    "    return group, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b28ab-7945-4558-aa05-f36a1d3fee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 3. Registry Dictionary\n",
    "classification_registry = {\n",
    "    'threshold': threshold_classifier,\n",
    "    'zscore': zscore_classifier\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d72b2-20cf-4858-a991-c42bda18fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 4. Apply Classification\n",
    "def classify_matrix(df, method='threshold'):\n",
    "    results = {}\n",
    "    classifier = classification_registry[method]\n",
    "\n",
    "    for attr_sn, row in df.iterrows():\n",
    "        group, confidence = classifier(row)\n",
    "        results[attr_sn] = {\n",
    "            'group': group,\n",
    "            'confidence': confidence,\n",
    "            'method': method\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d34f0d-0b83-4ef9-8479-e9ed5446305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 5. Embed into array_dict\n",
    "def embed_classification(array_dict, classification_results):\n",
    "    for dvt_key, result in classification_results.items():\n",
    "        if dvt_key in array_dict:\n",
    "            array_dict[dvt_key]['classification'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e463b-3c83-4b35-86c2-3f52cc57ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Optional Diagnostic\n",
    "def preview_classification(results, n=5):\n",
    "    for k in list(results.keys())[:n]:\n",
    "        print(f\"{k}: {results[k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3bd86-41c3-4c8c-bc86-ea7675266348",
   "metadata": {},
   "source": [
    "# **06_diagnostics.py**  |  *Overlay tools for inspecting metadata and classification*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b615ff5-4b49-43cd-a5b4-92ec00aa9a16",
   "metadata": {},
   "source": [
    "# **07_tests.py**  |  *Reproducible test cases and versioning checks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d60fd-80ed-4657-9988-1441f4bad47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c95ccb-1d2a-4648-9056-d04c40693787",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042c552-abd6-42ba-bf39-66876c883f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a6a18-606d-47ca-8648-0bbff50781f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
