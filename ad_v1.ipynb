{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d1664d-7240-4713-a26f-0026da29fb30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **This sbs array_dict with pickle v1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40277d-0c4e-4cb1-a3dc-e40f6bb25b12",
   "metadata": {},
   "source": [
    "# **00_setup.py** | *Refences & Imports, def_fnctna, glossary, config flags*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60ae91-135a-401c-b026-8aee7bc28167",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Refences & Help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbc1f1-68ff-45d7-9ecd-3a0cfa7c0e1b",
   "metadata": {},
   "source": [
    "**Modular Workbook for Array Dictionary Implementation**\n",
    "1. ***Help setting up the structure of a array_dict system and workbook***\n",
    "2. *https://copilot.microsoft.com/shares/pages/3HV5tomNJNNZi9VReAwN9*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731985b7-e1e2-4df5-8500-b0f9fc11a7c0",
   "metadata": {},
   "source": [
    "**Cross-Platform File Path Handling in Python**\n",
    "1. ***solving problems opening files in window, WWSL  and python***\n",
    "2. *https://copilot.microsoft.com/shares/pages/txcgXXLkjC8zGKTwGiCd1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22032b-7d0e-437a-b0c9-5fa37e305dfa",
   "metadata": {},
   "source": [
    "**Using Pathlib to Build File Paths in Python**\n",
    "1. ***Creatung paths in wsl is tricky using \"\"\"Pathlib\"\"\"to Build File Paths helps***\n",
    "2. *https://copilot.microsoft.com/shares/pages/SmGr7Zt8ZDNHvbidFGVZy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443aa0b-6386-4f7b-92cc-9594a6677e74",
   "metadata": {},
   "source": [
    "**WSL-Compatible File Path Handling in Python**\n",
    "1. ***variable to represent a file path in WSL***\n",
    "2. *https://copilot.microsoft.com/shares/pages/bdtSWCe2bNJPvKZSrvDXo*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ef4ff-ea59-4334-8d0e-d6f6112c5ae8",
   "metadata": {},
   "source": [
    "**Python Pickle Module Guide**\n",
    "1. ***explaination of Pickel reading and writing***\n",
    "2. *https://copilot.microsoft.com/shares/pages/qMbW8PsnCpjM1MW2EGH1z*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de248c68-8340-4da1-8061-bb7db60cd6bf",
   "metadata": {},
   "source": [
    "**Modular Batch Save/Load Utility for array_dict**\n",
    "1. ***loading many objects to pickle***\n",
    "2. *https://copilot.microsoft.com/shares/pages/TRT16QCyupBTnq8JwMuSU*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49860de7-9186-4f76-bb84-2255f21267ad",
   "metadata": {},
   "source": [
    "**Modular Pickle Utility Design**\n",
    "1. ***def functions to read and save Pickel***\n",
    "2. *https://copilot.microsoft.com/shares/pages/aeBducMjy6ZCcBzYBUW3h*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1074f-0d6c-45ef-9340-6ca9dd861d70",
   "metadata": {},
   "source": [
    "**Understanding Python Raw Strings**\n",
    "1. ***r\"\" is a an operater that instructs how to read the str it doew not change the str r\"xl_ada.csv\" and \"xl_ada.csv\" are identical once createdâ€”because there are no backslashes to escape.***\n",
    "2. *Understanding Python Raw Strings*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb39e27-73aa-43d3-a069-7a461d20eb00",
   "metadata": {},
   "source": [
    "## Imports,glossary, Def_function_utilities, config flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c6544-b1b6-4e9f-a6d4-a545c7d470ec",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2b69568-0542-40cb-90b9-cefdd5d0b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO =  \n",
      "base_path =  /home/bhuns\n",
      "REPO\\data =  \\data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "base_path = os.path.expanduser(\"~\")  # Gets /home/bhuns in WSL all measured from here\n",
    "REPO = \"\"\n",
    "#data = \" \\\" + \"_data\"\n",
    "print(\"REPO = \",REPO)\n",
    "print(\"base_path = \",base_path)\n",
    "print(\"REPO\\data = \",REPO + \"\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e1d9b-a410-4bda-a55d-325457688c9b",
   "metadata": {},
   "source": [
    "### Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3aa2ebaa-65a4-4a3d-971c-78784a61e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:bnm is abrev for base name [common name for a type of data]\n",
    "# bnm for  array_dict is \"ad\"          \n",
    "# bnm for  array_dict_serial number is \"ad_sn\" \n",
    "# bnm for attributes is att         # attributes\n",
    "# bnh for ad \"Lablel lookup table\"   is  \"ad_sn_ad_lbl\"     # \n",
    "# csv_pathway  is in  REPO               #bu with \"git\"\n",
    "# pkl files are in REPO/data           # not bu with \"git\"\n",
    "# csv_pathway = \"bnm.csv\"            # csv versions are in data folder to use git and allow normal version free git bu\n",
    "# pkl_pathway = r\"data/bnm.pkl\"      # pkl versions are in REPO/data to avoid git and allow bu\n",
    "# list of  bnm add new as arise  USE WITH READERS AND saveS TO FILES==================\n",
    "#bnm list in 01 [List of bnm [base_names] for arrays that need to be imported and formatted]----------------------------------------------\n",
    "#bnm =  \"ad_sn\"                        # array_sn_dict\n",
    "#bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "#bnm =  \"at_sn_\"                        # attrbts_sn_x_array_dict_sn\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64eb941-dab3-4119-bc71-61c77e1bdbf5",
   "metadata": {},
   "source": [
    "### Def_function_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66a738-5627-44d2-b25e-264f81015a17",
   "metadata": {},
   "source": [
    "#### load from  csv from a \"\"\"bnm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a745dabf-e3b6-49a8-9019-09291c74b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_csv(bnm):\n",
    "    \"\"\"Load object from csc file.\"\"\"\n",
    "    path_csv = f\"{bnm}.csv\"\n",
    "    str(path_csv)                           # change to string\n",
    "    path = Path(path_csv)\n",
    "    print(path_csv)\n",
    "    with open(path_csv, 'r', newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6db3281-7da0-4bb6-b631-0904a62f5354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_sn.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dvt': '45860', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''},\n",
       " {'dvt': '45861', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''},\n",
       " {'dvt': '45862', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''},\n",
       " {'dvt': '45863', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''},\n",
       " {'dvt': '45864', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''},\n",
       " {'dvt': '45865', 's000': '', 's001': '', 's002': '', 's003': '', 's004': ''}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnm =\"ad_sn\"\n",
    "Load_csv(bnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de783a-4ae4-4768-83e1-95ea7bf943f2",
   "metadata": {},
   "source": [
    "#### load from pkl from a \"\"\"bnm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df47a0-6777-4777-92cf-3f63a9d48db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(bmn):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    str(path_pkl)                           # change to string\n",
    "    print(path_pkl)\n",
    "    path = Path(path_pkl)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1bdd9-45a9-4701-8106-d36efa2812a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to  # def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "bnm =\"ad_sn\"\n",
    "load_pickle(bnm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456f667-90c8-40c0-8c73-7e9494927fad",
   "metadata": {},
   "source": [
    "#### Save to pkl from a \"\"\"bnm\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7d33b-28f1-402c-a051-bb9820517d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "def save_pkl(bnm):\n",
    "#    fl_nm(bnm)\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    str(path_pkl)                           # change to string\n",
    "    print(\"wsl folder: \",path_pkl)\n",
    "    save_pickle(bnm, path_pkl)\n",
    "    print(f\"Saving to: {path_pkl.resolve()}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ed049-62a6-4616-831a-841bcbed59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to  # def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "bnm =\"ad_sn\"\n",
    "save_pkl(bnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76558e-74b4-4631-b5b4-baa3d45fcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pkl = r\"data\\ \" + bnm + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d944fd5-e929-4215-a6bc-1163fff2dae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  path_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18da3c-4289-435f-879e-0792e7082dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def_function_utilities\n",
    "def fl_nm_csv(bnm):       # calc pathway for csv files from base name bnm -- can use function directly in file readers\n",
    "    fl_nm_csv = bnm + \".csv\"\n",
    "    return fl_nm_csv\n",
    "def fl_nm(bnm):           # calc pathway for pkl files from base name bnm -- can use function directly in file readers\n",
    "    fl_nm = bnm + \".pkl\"\n",
    "    return fl_nm\n",
    "\n",
    "# ---------------------------- pathway calc ----------------------------------------------------\n",
    "def pthwy_csv(bnm):       # calc pathway for csv files from base name bnm -- can use function directly in file readers\n",
    "    pthwy_csv = bnm + \".csv\"\n",
    "    return pthwy_csv\n",
    "def pthwy_pkl(bnm):           # calc pathway for pkl files from base name bnm -- can use function directly in file readers\n",
    "    pthwy_pkl =  r\"data/\" + bnm + \".pkl\"\n",
    "    return pthwy_pkl\n",
    "\n",
    "# example -------------------------------------------------------------------------------------------------------------\n",
    "#bnm = \"ad_sn\"\n",
    "#pthwy_csv(bnm)\n",
    "# answer  'data/ad_sn.csv'  \n",
    "# pd.read_csv(pthwy_csv(bnm))\n",
    "\n",
    "#------------------ðŸ§± Basic Pickle Save/Load Utility------------------------------------\n",
    "def save_pickle(obj, path):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(\"loaded pkl = \",path)\n",
    "def load_pickle(path):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "#------------------ðŸ§± Basic csv Save/Load Utility------------------------------------\n",
    "# dict --------------------------------------------------------------------------\n",
    "def save_csv(data, path):\n",
    "    \"\"\"save list of dicts to CSV.\"\"\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        save = csv.Dictsave(f, fieldnames=data[0].keys())\n",
    "        save.saveheader()\n",
    "        save.saverows(data)\n",
    "def read_csv(path):\n",
    "    \"\"\"Read CSV into list of dicts.\"\"\"\n",
    "    with open(path, 'r', newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return list(reader)\n",
    "\n",
    "# 2D array -----------------------------------------------------------------\n",
    "def save_2d_csv(array2d, path):\n",
    "    \"\"\"save 2D array (list of lists) to CSV.\"\"\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        save = csv.save(f)\n",
    "        save.saverows(array2d)\n",
    "def read_2d_csv(path):\n",
    "    \"\"\"Read CSV into 2D array (list of lists).\"\"\"\n",
    "    with open(path, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0309b-23a9-4d4a-8100-40b58ba4cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a472e1f-7a53-4e97-b6a7-5e46f4cc8903",
   "metadata": {},
   "source": [
    "# **01_array_loader.py** |  *Load data arrays from (csv and/or pkl files) format them into the required system data structures ie ***array_dict*** !*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac366f1-3487-457c-9281-8dae8e15c1ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## List of bnm [base_names] for arrays that need to be imported and formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69dc314-48bf-444b-8bf2-2d74605940bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of bnm [base_names] for arrays that need to be imported and formatted\n",
    "#bnm =  \"ad_sn\"                        # array_sn_dict \n",
    "#bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "#bnm =  \"at_sn_\"                       # attrbts_sn_x_array_dict_sn\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#bnm =  \"ad_sn\"                        # array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8465d-c758-4ff1-b355-31a3c0acbb3d",
   "metadata": {},
   "source": [
    "## Import bnm [base_name]  to arrays then format to data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d430fd-d84a-4053-b115-f8365e6f86ca",
   "metadata": {},
   "source": [
    "### 0. Process steps & def definition & examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a3156-81f9-4480-86b3-f7f04b30f1bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Diagnostic only for path calcs atored in RAW change to CODE mode to test\n",
    "bnm = \"ad_sn\"\n",
    "pthwy_csv(bnm)                      # calc pathway for csv files from base name bnm -- can use function directly in file reader\n",
    "pthwy(bnm)                       # calc pathway for pkl files from base name bnm -- can use function directly in file reader\n",
    "print(\" bnm & csv & pkl pathway for verification\")   # print verification\n",
    "print(\" bnm =\",bnm,\"\\n\",\"pthwy_csv =\",pthwy_csv(bnm),\"\\n\",\"pthwy =\",pthwy(bnm))              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df5cb0-b880-4bda-8871-f65a1ddfdbd4",
   "metadata": {},
   "source": [
    "#### 2 import from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb391b-166e-4103-a153-5f6c45bac642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bnm and run\n",
    "bnm = \"ad_sn\"\n",
    "df = pd.read_csv(pthwy_csv(bnm))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f700b90-3a5b-4e57-84af-6212ecf4edbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f156f964-5e93-4785-8a33-cb7acef471f0",
   "metadata": {},
   "source": [
    "#### 2 export to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcea89e-25df-4035-b775-a358900a09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm = \"ad_sn1\"\n",
    "save_pickle(bnm,pthwy(bnm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2853d2d-2e6e-4cb8-8adc-abb96c432559",
   "metadata": {},
   "source": [
    "#### 3 format for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da68ae8-8836-4f3f-915d-79c49009d348",
   "metadata": {},
   "source": [
    "#### l calc pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6eb431-591e-483c-b648-56b8ccf03c45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Apply to bmn list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97af60d-07e4-435a-a56a-28e163dbb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pathway for bnm\n",
    "# load bmn array frome file\n",
    "# format is it for use by procecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbeed48-5c32-49f9-b592-dc3fb82581a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old ===============================================================================\n",
    "# Retreive  xl_ad_sn from .csl\n",
    "# Define the path (reset path to WSL preventing possible p errors)\n",
    "\n",
    "# since working in the ubuntu terminal use WSL rules ie r\" path \"\n",
    "base_path = os.path.expanduser(\"~\")  # Gets /home/bhuns in WSL\n",
    "csv_path = os.path.join(base_path, c)\n",
    "\n",
    "# Load with headers\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert to NumPy array (excluding headers)\n",
    "xl_ad_sn = df.to_numpy()\n",
    "#xl_ad_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f73450-e7b2-4d59-a36f-9d8c90e9524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a2685-1688-44e9-9b8c-5bf1309fbdbe",
   "metadata": {},
   "source": [
    "#### l calc pathway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ac38f-dd84-4bf5-bf21-cfae1ef6bd69",
   "metadata": {},
   "source": [
    "# **02_array_dict_builder.py**   |  *Transform arrays into array_dict with metadata*\n",
    "_ ***Script Update for Data Dictionary Creation** link *https://copilot.microsoft.com/shares/pages/jLLrDDP9aZqQjatwkyFfr*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb8ff7-8caf-4029-896e-5fc56b38b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and isolate the raw headers from \"xl_ad_sn_hdr,csl\"\n",
    "# Load CSV\n",
    "\n",
    "\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Inspect raw headers\n",
    "raw_headers = df.columns.tolist()\n",
    "#print(\"Raw headers:\", raw_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977397a-44e3-406b-af83-5dc193a83366",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# âœ… Full Setup >> headers >> dtv_index >> array_dict\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)         # read array from \"csv_path\"\n",
    "\n",
    "# Extract headers and data\n",
    "headers = df.columns.tolist()\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "# Locate the index of the 'dtv' column\n",
    "dtv_index = headers.index('dtv')\n",
    "\n",
    "# Build array_dict\n",
    "array_dict = {}\n",
    "\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928214d4-84af-473c-a5dc-2399342ff359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ðŸ§ª Verify the construction\n",
    "\n",
    "for dtv, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DTV: {dtv}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a91b41-4db5-4c9d-aabc-806c4b3210d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Continue Building array_dict\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "array_dict = {}\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(raw_headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a6b3c-3baf-4d77-a632-e4e0f3d7502b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for dvt, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DVT: {dvt}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f33a7-965a-48dc-a670-10dfebc56ad2",
   "metadata": {},
   "source": [
    "# 03 Setting the classification of \"dat_col\"s with attribts stored in files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1be936-396b-470c-8f53-adf7c0b884fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacebebe-f719-4569-bf24-f8e13493c97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Metadata Injection Function in Python**\n",
    "_\n",
    "*https://copilot.microsoft.com/shares/pages/LpNfiWnk3ndWRko9EnfxS*\n",
    "\n",
    "_Question *I would like like to have function that would accept a \"dat_col_sn\" and and a \"attribut_sn\" and read the \"value\" in that item in the file \"attrbts_sn_x_dat_col_sn\" and set that \"attribute\" in that \"dat_col\" to that \"value\". If the class & attrbute did not exist, it would create one. Js that possible.*\n",
    "\n",
    "Absolutely, Billâ€”thatâ€™s not only possible, itâ€™s a great example of modular, operator-driven metadata injection. Youâ€™re describing a function that:\n",
    "\n",
    "Accepts a dat_col_sn (e.g. 's003') and an attribute_sn (e.g. 'a001')\n",
    "\n",
    "Looks up the value at that coordinate in a matrix file (e.g. CSV or Excel)\n",
    "\n",
    "Injects that value into the corresponding array_dict[dat_col_sn]['attributes'][attribute_sn]\n",
    "\n",
    "Creates the attribute if it doesnâ€™t exist\n",
    "\n",
    "Letâ€™s scaffold that cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00a24f-c55c-4746-b2a3-8e36c11f0c8a",
   "metadata": {},
   "source": [
    "## ðŸ§  Function: inject_attribute_from_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4da89-e8e1-4563-b31d-42123ae0a2dd",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc222d44-63c7-486b-8b31-199d3c8cb2fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. The matrix file is named \"attrbts_sn_x_dat_col_sn.csv\" ..................ok  [matrix_path]\n",
    "2. Rows = attribute_sn (e.g. 'a000', 'a001')................................ok\n",
    "3. Columns = dat_col_sn (e.g. 's000', 's001')...............................ok\n",
    "4. Youâ€™ve already built array_dict keyed by dat_col_sn.........need to load ##\n",
    "\"\\\\wsl.localhost\\Ubuntu\\home\\bhuns\\JL_1\\data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "r\"data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "\"attrbts_sn_x_dat_col_sn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5697a9a-c574-4078-9f7c-1f59ef049dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"attrbts_sn_x_dat_col_sn.csv\"\n",
    "df = read_wsl_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4ff18-12c1-4e6c-8760-a0d350f6203e",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d282555-ebff-4634-9265-f243e0e69cda",
   "metadata": {},
   "source": [
    "#### inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822aaf6-b7cb-4915-9f47-23f759e540bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "\n",
    "def inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "    # Load matrix\n",
    "    df = pd.read_csv(matrix_path, index_col=0)  # Assumes first column is attribute_sn\n",
    "\n",
    "    # Validate existence\n",
    "    if attribute_sn not in df.index:\n",
    "        raise ValueError(f\"Attribute '{attribute_sn}' not found in matrix rows.\")\n",
    "    if dat_col_sn not in df.columns:\n",
    "        raise ValueError(f\"Data column '{dat_col_sn}' not found in matrix columns.\")\n",
    "\n",
    "    # Extract value\n",
    "    value = df.at[attribute_sn, dat_col_sn]\n",
    "\n",
    "    # Inject into array_dict\n",
    "    if dat_col_sn not in array_dict:\n",
    "        raise KeyError(f\"Data column '{dat_col_sn}' not found in array_dict.\")\n",
    "\n",
    "    entry = array_dict[dat_col_sn]\n",
    "    if 'attributes' not in entry:\n",
    "        entry['attributes'] = {}\n",
    "\n",
    "    entry['attributes'][attribute_sn] = value\n",
    "\n",
    "    return value  # Optional: return for confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72aaad-bc23-4809-87f1-21e7f7b5a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ§ª Example Usage\n",
    "matrix_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/attrbts_sn_x_dat_col_sn.csv\")\n",
    "value = inject_attribute_from_matrix(array_dict, 's003', 'a001', matrix_path)\n",
    "\n",
    "print(f\"Injected value: {value}\")\n",
    "print(array_dict['s003']['attributes']['a001'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92183b-390b-4102-abe4-26f1fd701bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### ðŸ” Optional Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b019af2-6819-4602-95e7-a49ccdc9d8d6",
   "metadata": {},
   "source": [
    "Add logging or provenance tags\n",
    "\n",
    "Support batch injection for all attributes or all columns\n",
    "\n",
    "Validate types or ranges before injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f05d5-f155-4ff5-8d9e-7bc4a3b4f885",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0489f-7e62-4302-a7d9-408d6294530d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa619ee3-c338-4249-9d6c-9e391a584836",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6236d-e13d-4968-8c9a-d9c24598624e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3906b6-b0b1-4858-bd06-e6684dac4c36",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39df37d-95c7-4f9c-91bd-c1eb34ee2aad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81456798-0e17-428d-801a-171eed22c9f8",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c18f0-484b-48e4-a843-582ec26cd54c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be694f8-e508-4ad8-9e79-024d0ba2e7a1",
   "metadata": {},
   "source": [
    "# **04_gui_selector.py**  |  *Operator-driven GUI for selecting and grouping entries*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c5dfb-6795-47ed-be00-c950416bf641",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **05_storage_utils.py**  |  *Save/load using Pickle, Excel, HDF5*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d2ff6-add0-449c-932d-96d117f241e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# **0?_classification_registry.py**  |  *Define classification args, flags, and validation logic*\n",
    "_***Wrking but funct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707113e-7e27-414f-9c6e-a89fcfe1e908",
   "metadata": {},
   "source": [
    "**Classification Registry Implementation** \n",
    "_ *https://copilot.microsoft.com/shares/pages/P91viiY6QzR3Mp4WUnbFf*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375551f-c4a6-4ad2-8526-15cbe23d5b7f",
   "metadata": {},
   "source": [
    "## ðŸ§  Classification Registry Scaffold (classification_registry.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86b3d7-94b9-4fca-93c1-79cf5d508ecd",
   "metadata": {},
   "source": [
    "### Perfect, Bill. Youâ€™ve got a classification matrix scaffoldedâ€”rows as attribute_sn (e.g. a000, a001, ...) and columns as dat_col.sn (e.g. s000, s001, ...). \n",
    "1. Thatâ€™s a great foundation for a modular classification registry.\n",
    "2. Letâ€™s build a separate fileâ€”say, classification_registry.pyâ€”that can:\n",
    "3. Load and validate the matrix\n",
    "4. Apply classification logic per attribute or per column\n",
    "5. Track provenance and confidence\n",
    "6. Return structured results for embedding into array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54d75e-5f66-43af-8beb-58aba94c6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ðŸ”¹ 1. Load the Matrix\n",
    "\n",
    "def load_classification_matrix(path):\n",
    "    df = pd.read_csv(path)  # or pd.read_excel\n",
    "    df.index.name = 'attribute_sn'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce72b28-ce58-45f4-8d33-d3bdd00ebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 2. Define Classification Methods\n",
    "def threshold_classifier(row, threshold=0.5):\n",
    "    score = row.mean()\n",
    "    group = 'A' if score > threshold else 'B'\n",
    "    confidence = round(abs(score - threshold), 3)\n",
    "    return group, confidence\n",
    "\n",
    "def zscore_classifier(row):\n",
    "    z = (row - row.mean()) / row.std()\n",
    "    group = 'High' if z.mean() > 1 else 'Low'\n",
    "    confidence = round(z.std(), 3)\n",
    "    return group, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b28ab-7945-4558-aa05-f36a1d3fee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 3. Registry Dictionary\n",
    "classification_registry = {\n",
    "    'threshold': threshold_classifier,\n",
    "    'zscore': zscore_classifier\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d72b2-20cf-4858-a991-c42bda18fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 4. Apply Classification\n",
    "def classify_matrix(df, method='threshold'):\n",
    "    results = {}\n",
    "    classifier = classification_registry[method]\n",
    "\n",
    "    for attr_sn, row in df.iterrows():\n",
    "        group, confidence = classifier(row)\n",
    "        results[attr_sn] = {\n",
    "            'group': group,\n",
    "            'confidence': confidence,\n",
    "            'method': method\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d34f0d-0b83-4ef9-8479-e9ed5446305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ 5. Embed into array_dict\n",
    "def embed_classification(array_dict, classification_results):\n",
    "    for dvt_key, result in classification_results.items():\n",
    "        if dvt_key in array_dict:\n",
    "            array_dict[dvt_key]['classification'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e463b-3c83-4b35-86c2-3f52cc57ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Optional Diagnostic\n",
    "def preview_classification(results, n=5):\n",
    "    for k in list(results.keys())[:n]:\n",
    "        print(f\"{k}: {results[k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3bd86-41c3-4c8c-bc86-ea7675266348",
   "metadata": {},
   "source": [
    "# **06_diagnostics.py**  |  *Overlay tools for inspecting metadata and classification*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b615ff5-4b49-43cd-a5b4-92ec00aa9a16",
   "metadata": {},
   "source": [
    "# **07_tests.py**  |  *Reproducible test cases and versioning checks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d60fd-80ed-4657-9988-1441f4bad47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c95ccb-1d2a-4648-9056-d04c40693787",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042c552-abd6-42ba-bf39-66876c883f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a6a18-606d-47ca-8648-0bbff50781f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
