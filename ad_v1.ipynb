{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d1664d-7240-4713-a26f-0026da29fb30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# **This sbs array_dict with pickle v1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40277d-0c4e-4cb1-a3dc-e40f6bb25b12",
   "metadata": {},
   "source": [
    "# **00_setup.py** | *Refences & Imports, def_fnctna, glossary, config flags*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41897223-32cd-4a03-8c9a-5d34fdea2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dc820-6081-4882-bfc5-fd037d6893a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f60ae91-135a-401c-b026-8aee7bc28167",
   "metadata": {},
   "source": [
    "## References & Help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a6f04-f3b2-4cf8-9e2c-9b46cc341af9",
   "metadata": {},
   "source": [
    "**Setup the labtop as a clone of my desktop.**\n",
    "1. ***Preparing the laptob and the use git to sychrnise***\n",
    "2. *https://copilot.microsoft.com/shares/q3aDrtDkNPVtV5LMG3eYy*\n",
    "3. *https://copilot.microsoft.com/shares/rpf9DEopemokLhaR4bXsM*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbc1f1-68ff-45d7-9ecd-3a0cfa7c0e1b",
   "metadata": {},
   "source": [
    "**Modular Workbook for Array Dictionary Implementation**\n",
    "1. ***Help setting up the structure of a array_dict system and workbook***\n",
    "2. *https://copilot.microsoft.com/shares/pages/3HV5tomNJNNZi9VReAwN9*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731985b7-e1e2-4df5-8500-b0f9fc11a7c0",
   "metadata": {},
   "source": [
    "**Cross-Platform File Path Handling in Python**\n",
    "1. ***solving problems opening files in window, WWSL  and python***\n",
    "2. *https://copilot.microsoft.com/shares/pages/txcgXXLkjC8zGKTwGiCd1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22032b-7d0e-437a-b0c9-5fa37e305dfa",
   "metadata": {},
   "source": [
    "**Using Pathlib to Build File Paths in Python**\n",
    "1. ***Creatung paths in wsl is tricky using \"\"\"Pathlib\"\"\"to Build File Paths helps***\n",
    "2. *https://copilot.microsoft.com/shares/pages/SmGr7Zt8ZDNHvbidFGVZy*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443aa0b-6386-4f7b-92cc-9594a6677e74",
   "metadata": {},
   "source": [
    "**WSL-Compatible File Path Handling in Python**\n",
    "1. ***variable to represent a file path in WSL***\n",
    "2. *https://copilot.microsoft.com/shares/pages/bdtSWCe2bNJPvKZSrvDXo*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ef4ff-ea59-4334-8d0e-d6f6112c5ae8",
   "metadata": {},
   "source": [
    "**Python Pickle Module Guide**\n",
    "1. ***explaination of Pickel reading and writing***\n",
    "2. *https://copilot.microsoft.com/shares/pages/qMbW8PsnCpjM1MW2EGH1z*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de248c68-8340-4da1-8061-bb7db60cd6bf",
   "metadata": {},
   "source": [
    "**Modular Batch Save/Load Utility for array_dict**\n",
    "1. ***loading many objects to pickle***\n",
    "2. *https://copilot.microsoft.com/shares/pages/TRT16QCyupBTnq8JwMuSU*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49860de7-9186-4f76-bb84-2255f21267ad",
   "metadata": {},
   "source": [
    "**Modular Pickle Utility Design**\n",
    "1. ***def functions to read and save Pickel***\n",
    "2. *https://copilot.microsoft.com/shares/pages/aeBducMjy6ZCcBzYBUW3h*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1074f-0d6c-45ef-9340-6ca9dd861d70",
   "metadata": {},
   "source": [
    "**Understanding Python Raw Strings**\n",
    "1. ***r\"\" is a an operater that instructs how to read the str it doew not change the str r\"xl_ada.csv\" and \"xl_ada.csv\" are identical once created—because there are no backslashes to escape.***\n",
    "2. *Understanding Python Raw Strings*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a8f7c-51d6-4a82-be41-58880589520b",
   "metadata": {},
   "source": [
    "**CSV Editing and Saving Workflow**\n",
    "1. ***This loads the dat_col dict for .csv file and then after editing replace the updated version into same file***\n",
    "2. *https://copilot.microsoft.com/shares/pages/QabFDtDG8Utc8EFMgzzyz*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4dbdf-cf46-4cd3-b173-cfb9728efa7b",
   "metadata": {},
   "source": [
    "**Ordered Dictionary with 'dvt' First in Python**\n",
    "1. ***This reads a 2D array with headers from .csv file and makes a std dat_obj like [ad_sn]***\n",
    "2. *https://copilot.microsoft.com/shares/pages/3iojVoSLAcCggGcWtxUmM*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eccb42-1e40-458c-a9fa-75c29b27a41e",
   "metadata": {},
   "source": [
    "**Optimizing Data Types for Memory Efficiency**\n",
    "1. ***This should be used before I start expanding***\n",
    "2. *https://copilot.microsoft.com/shares/pages/wGUNBVFLcxarPtGE1mwnP*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a0b36-69be-464f-ab8d-b878382ca3db",
   "metadata": {},
   "source": [
    "**Using try: on the index col**\n",
    "1. ***Try: ia valuable tool used with index method of panda***\n",
    "2. *https://copilot.microsoft.com/shares/pages/iqre2v246hhjkauLu1CGG*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ddfa3-78fa-4269-924f-fc01d9ba6c8f",
   "metadata": {},
   "source": [
    "**Calculatioing names of load and save results**\n",
    "1. ***Complicated way to calculate namees of functions results***\n",
    "2. *https://copilot.microsoft.com/shares/pages/kzs5ZkCweSW2g8TEVWwBY*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b7826-8d51-4b38-8cd8-b0e42c37819b",
   "metadata": {},
   "source": [
    "**Function Registry**\n",
    "1. ***Build a registry to hold and call functions***\n",
    "2. *https://copilot.microsoft.com/shares/VAT6QDNijDghzbWkei5fV*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d923213-f6dc-4d9a-8e41-56ee7e1e2fa8",
   "metadata": {},
   "source": [
    "**🧩 Step-by-Step: Assign \"CoQ10\" as a ResourceLoader Instance\"**\n",
    "1. ***create an instance of a certain class***\n",
    "2. *https://copilot.microsoft.com/shares/PfLQMHCkQZXy9RoHAerAZ*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6aaa3-d3f8-418e-97c1-e6f05c5dff2e",
   "metadata": {},
   "source": [
    "**Produce an instance of that class for each dat_col**\n",
    "1. ***Once you define a class that includes attributes like name and normal_dose, and then apply it to each item in your dat_col, running __init__ will produce an instance of that class for each item..***\n",
    "2. *https://copilot.microsoft.com/shares/VAT6QDNijDghzbWkei5fV*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b1f58-e8a9-4efe-bb0a-5f74511fcc3d",
   "metadata": {},
   "source": [
    "**List of copilot pages on Classes**\n",
    "1. ***buils class system links in reverse order***\n",
    "2. *https://copilot.microsoft.com/shares/YZwoHgYtMtPo9mySMxHQL* ***Inheritance-Based Classification Scaffold***\n",
    "3. *https://copilot.microsoft.com/shares/dgoHQbZaYRVMaC7teBiqX*\n",
    "4. *https://copilot.microsoft.com/shares/qASaQdp29maniC2mDnY4h*\n",
    "5. *https://copilot.microsoft.com/shares/vnTrfzUidrguteQgZuSNU*\n",
    "6. *https://copilot.microsoft.com/shares/TWNAfv6ubx8z2bAiLA8oX*\n",
    "7. *https://copilot.microsoft.com/shares/reShWjrM9yt9Hgu1HNVk7*\n",
    "8. *https://copilot.microsoft.com/shares/HAtG3uKHezAPpYNWdwZBv*\n",
    "9. *https://copilot.microsoft.com/shares/MApX5LfmaD2ipvn65PihY* ***Why Dual Instancing of dat_col Is Safe and Smart***\n",
    "10. *https://copilot.microsoft.com/shares/HSFhgptLeXqQe8MuDp31k* ***When i commt to git and shut down, will I be able to use the class operaters to generate instances when I restart.***\n",
    "11. *https://copilot.microsoft.com/shares/i72SNPPtQBbav6fsu4cT4* ***Here's a restart-ready bootstrap scaffold that wires together your canonical loader, filtering class, and diagnostic overlays. It’s modular, traceable, and operator-friendly—just how you like it.***\n",
    "12. *https://copilot.microsoft.com/shares/JXNEwRKMDoigkwLMymtbd* ***When i commt to git and shut down, will I be able to use the class operaters to generate instances when I restart.***\n",
    "13.  next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8be22-ee3a-423f-afcd-5a6186fd04a4",
   "metadata": {},
   "source": [
    "**JupyterLab is a great sandbox for building and visualizing hierarchical structures like ancestral trees, signal pathways, and organizational charts**\n",
    "1. ***Build a strategy for diagrams built in jupyterlab***\n",
    "2. *https://copilot.microsoft.com/shares/xGFuAUQg6yJZ62g3HayrQ* **all options for diagraming in JL**\n",
    "3. https://copilot.microsoft.com/shares/DvFDux4kBCxokgYujPS7x   **pick final approach for diagrams inJL**\n",
    "4. *https://copilot.microsoft.com/shares/MjejKcx6aTazHEp3HK4JL* ***explanation and scaffold***\n",
    "5. * https://copilot.microsoft.com/shares/pWonoyBkJ3DYQacVespbd* ***converts the diagram loader to a function*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbbe35-9a7c-42b1-9e6a-47c61c2eadb8",
   "metadata": {},
   "source": [
    "**Function Registry**\n",
    "1. ***Build a registry to hold and call functions***\n",
    "2. *https://copilot.microsoft.com/shares/VAT6QDNijDghzbWkei5fV*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969e98f-b7c7-4928-9a42-c00766f374e6",
   "metadata": {},
   "source": [
    "**Function Registry**\n",
    "1. ***Build a registry to hold and call functions***\n",
    "2. *https://copilot.microsoft.com/shares/VAT6QDNijDghzbWkei5fV*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fae4b7-7c51-4ef3-90f5-d0995223ebe5",
   "metadata": {},
   "source": [
    "**📱 iPhone Input Strategies for dat_col Dicts**\n",
    "1. ***use cell phones to enter daily data***\n",
    "2. *https://copilot.microsoft.com/shares/wsUJ7hi4LfdANpwz4njf3*  ***selecting strategy***\n",
    "3. https://copilot.microsoft.com/shares/xCioyq4yenpv714NtzLeC * ***designing in Jupyter labs***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb39e27-73aa-43d3-a069-7a461d20eb00",
   "metadata": {},
   "source": [
    "## Imports,glossary, Def_function_utilities, config flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c6544-b1b6-4e9f-a6d4-a545c7d470ec",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b69568-0542-40cb-90b9-cefdd5d0b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO =  \n",
      "base_path =  /home/bhuns\n",
      "REPO\\data =  \\data\n",
      "sys.executable =  /home/bhuns/miniconda3/envs/scu/bin/python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "base_path = os.path.expanduser(\"~\")  # Gets /home/bhuns in WSL all measured from here\n",
    "REPO = \"\"\n",
    "#data = \" \\\" + \"_data\"\n",
    "print(\"REPO = \",REPO)\n",
    "print(\"base_path = \",base_path)\n",
    "print(\"REPO\\data = \",REPO + \"\\data\")\n",
    "print(\"sys.executable = \",sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e1d9b-a410-4bda-a55d-325457688c9b",
   "metadata": {},
   "source": [
    "### Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2355f14-340f-4664-978a-3ce3f8f63413",
   "metadata": {},
   "source": [
    "xl lists def functions  bnms  ......"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72c54819-04f3-4ac3-8541-1ccd22948717",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# glossary list ------------------------------------------------------------------\n",
    "# Note:bnm is abrev for base name [common name for a type of data]\n",
    "# bnm for def_fnc_lst is \"def\"\n",
    "# bnm for  array_dict is \"ad\"          \n",
    "# bnm for  array_dict_serial number is \"ad_sn\" \n",
    "# bnm for attributes is att         # attributes\n",
    "# bnh for ad \"Lablel lookup table\"   is  \"ad_sn_ad_lbl\"     # \n",
    "# bnm list in 01 [List of bnm [base_names] for arrays that need to be imported and formatted]----------------------------------------------\n",
    "# bnm =  \"ad_sn\"                        # array_sn_dict\n",
    "# bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "# bnm =  \"at_sn_\"                        # attrbts_sn_x_array_dict_sn\n",
    "# bnm =  \"ad_sn\"                        # array_dict\n",
    "# bnm =  \"ad_sn\"                        # array_dict\n",
    "#adsn = the temp \"array_dict_sn\"  that is being worked on\n",
    "# csv_pathway  is in  REPO               #bu with \"git\"\n",
    "# pkl files are in REPO/data           # not bu with \"git\"\n",
    "# csv_pathway = \"bnm.csv\"            # csv versions are in data folder to use git and allow normal version free git bu\n",
    "# pkl_pathway = r\"data/bnm.pkl\"      # pkl versions are in REPO/data to avoid git and allow bu\n",
    "# list of  bnm add new as arise  USE WITH READERS AND saveS TO FILES=================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac366f1-3487-457c-9281-8dae8e15c1ef",
   "metadata": {},
   "source": [
    "#### List of bnm [base_names] for arrays that need to be imported and formatted"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe81db4-38e9-41c2-be5d-86faf1190f01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# List of bnm [base_names] for arrays that need to be imported and formatted\n",
    "#bnm =  \"ad_sn\"                        # array_sn_dict \n",
    "#bnm =  \"ad_sn_hdr\"                    # glssy_sn_hdr\n",
    "#bnm =  \"at_sn_\"                       # attrbts_sn_x_array_dict_sn\n",
    "#bnm =  \"ad_sn\"                        # array_dict\n",
    "#bnm =  \"ad_sn\"                        # array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64eb941-dab3-4119-bc71-61c77e1bdbf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Def_function_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5276f6a-6d4f-4c1b-9fd2-8b90df23dcbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### array load/save policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70acfd2-42c7-4d1a-ad9e-5488d9f6eace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. Full Round trip def function\n",
    "2. for csv storage\n",
    "3. from a **\"bnm\"** [Basic data class Name]\n",
    "4. and a **adsn** [Array Dict Serial Number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f44589-01e3-4359-b704-8d5ab74e3c01",
   "metadata": {},
   "source": [
    "#### Utilities >>> contents of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "866ba99d-bb8f-4a2a-b598-51cb70ae56f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (1746734617.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mad_an for name, ad_an in globals().items() if isinstance(val, pd.DataFrame)]\u001b[39m\n                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "# if name is in directory\n",
    "ad_an for name, ad_an in globals().items() if isinstance(val, pd.DataFrame)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae60f24c-7266-4d39-bfa7-7eb67d37f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'OrderedDict',\n",
       " 'Out',\n",
       " 'Path',\n",
       " 'REPO',\n",
       " '_',\n",
       " '_1',\n",
       " '_3',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__session__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i2',\n",
       " '_i3',\n",
       " '_i4',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'base_path',\n",
       " 'csv',\n",
       " 'datetime',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'np',\n",
       " 'open',\n",
       " 'os',\n",
       " 'pd',\n",
       " 'pickle',\n",
       " 'quit',\n",
       " 'tk']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all namees in directory\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d30379-eee5-434e-a95e-26065173920d",
   "metadata": {},
   "source": [
    "#### defs/calls >>> 1 load_pickle(bmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a8657-6ce7-444b-9d9a-db6d9fed9715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(bmn):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    str(path_pkl)                           # change to string\n",
    "    path = Path(path_pkl)\n",
    "    print(bnm, \">>> is pickled to >>> :\",path_pkl)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b740ec9e-4c28-4d2a-9684-3d27ed96cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_sn >>> is pickled to >>> : data/ad_sn.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ad_sn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnm = \"ad_sn\"            # this is file where loads in data\n",
    "load_pickle(bnm)\n",
    "                                                             #Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf75312-74fc-4dd5-aeed-a6b9dc1ac990",
   "metadata": {},
   "source": [
    "#### defs/calls >>> 2 save_pickle(bmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bdfce7-efe5-48bb-bb19-72d656e7bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, bnm):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path_pkl = Path(\"data\") / f\"{bnm}.pkl\"\n",
    "    print (obj, \"is recorded to pickle file > \",path_pkl)\n",
    "    with path_pkl.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77160265-c8ab-4e52-8c55-d06d41f1e05d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#raw?\n",
    "bmn = \"ad_sn\"\n",
    "obj= ad_sn\n",
    "save_pickle(obj, bnm)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f66dca-8f40-47f2-9f6d-6c66ac57f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e3237f-a4c8-4cec-ab06-3097ab1aed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad_sn'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f247bc9-8cf9-49df-b590-a138436a8e73",
   "metadata": {},
   "source": [
    "#### defs/calls >>> 3a load_csv_to_df(bnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac390f03-a857-4476-b948-f5c6faa48f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_df(bnm):\n",
    "    path_csv = Path(f\"{bnm}.csv\")\n",
    "    #path_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db6821-df7a-49a0-9176-a163a9b217ec",
   "metadata": {},
   "source": [
    "#### defs/calls >>> 3b load_csv_to_dtv_dict(bnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390aceb1-30c8-4ad1-b5fc-76b8127165c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (524616303.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mC    \"\"\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "def load_csv_to_dict(bnm):\n",
    "C    \"\"\"\n",
    "    Load CSV into DataFrame and convert to ordered dict with 'dvt' first.\n",
    "    Sets 'dvt' as string index for direct access.\n",
    "    \"\"\"\n",
    "    path_csv = Path(f\"{bnm}.csv\")\n",
    "    df = pd.read_csv(path_csv)\n",
    "    print(df)\n",
    "    # Ensure 'dvt' is string before setting index\n",
    "    df['dvt'] = df['dvt'].astype(str)\n",
    "    df.set_index('dvt', inplace=True)\n",
    "\n",
    "    # Build ordered dictionary with 'dvt' as first key\n",
    "    obj = OrderedDict()\n",
    "    obj['dvt'] = df.index.tolist()\n",
    "\n",
    "    for col in df.columns:\n",
    "        #obj[col] = df[col].tolist()  # converts to panda series\n",
    "        obj[col] = df[col].to_numpy() # converts to numpy\n",
    "    print(obj)\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adc0c669-90ab-47e1-873d-ccc400925764",
   "metadata": {},
   "source": [
    "bnm = \"ad_sn\"         \n",
    "\"\"\"\n",
    "the file \"bhn\" is equal to obj_name.\n",
    "quotes around the \"name\" refers to the name of the obj to be saved\n",
    "the --name-- of \n",
    "the object refers to the content of the object.\n",
    "\n",
    "\"\"\"\n",
    "obj = load_csv_to_dict(bnm) \n",
    "ad_sn = obj         # in csv load must set file = object name\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45a13991-b235-4a27-819d-901d1a0350fb",
   "metadata": {},
   "source": [
    "ad_sn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44339c17-d5a1-4eb3-b640-8f01edf6805f",
   "metadata": {},
   "source": [
    "obj\n",
    "ad_sn = obj\n",
    "ad_sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da44c62b-70e0-48b8-a823-f0c2015de911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ad_sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e77b29-1609-406c-b4a8-ab996f39448a",
   "metadata": {},
   "source": [
    "#### defs/calls >>> make an upload to load pkl after xl edit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6e41f-33e7-4979-8e2b-5a5e023d58d5",
   "metadata": {},
   "source": [
    "#### defs/calls >>>  4 save_csv(bnm, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37894e6-78ed-4d66-b336-4d8ce1826783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Dictionary to csv in REPO\\\n",
    "# Note it converts to df and saves!!!!!!!\n",
    "def save_csv(bnm, obj):\n",
    "    \"\"\"\n",
    "    Reconstruct DataFrame from edited dictionary and overwrite original CSV.\n",
    "    Assumes 'dvt' is present as the first key in obj.\n",
    "    \"\"\"\n",
    "    # Rebuild DataFrame from dictionary\n",
    "    df_out = pd.DataFrame(obj)\n",
    "\n",
    "    # Ensure column order starts with 'dvt'\n",
    "    Lcols = ['dvt'] + [col for col in df_out.columns if col != 'dvt']\n",
    "    df_out = df_out[cols]\n",
    "\n",
    "    # Write back to original file\n",
    "    path_csv = f\"{bnm}.csv\"\n",
    "    df_out.to_csv(path_csv, index=False)\n",
    "    #print(\"saved to file > \",path_csv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11f627e8-5d4d-4e15-aab4-e876cbb2fb67",
   "metadata": {},
   "source": [
    "bnm = \"ad_sn\"\n",
    "obj = \"ad_sn\"  # assuming array_dict is your metadata-rich dictionary\n",
    "save_csv(bnm, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "558489c6-6740-4e0e-9797-62ecbcfae3fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m bnm = \u001b[33m\"\u001b[39m\u001b[33mad_sn\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m obj = array_dict[bnm]  \u001b[38;5;66;03m# assuming array_dict is your metadata-rich dictionary\u001b[39;00m\n\u001b[32m      4\u001b[39m save_csv(bnm, obj)\n",
      "\u001b[31mNameError\u001b[39m: name 'array_dict' is not defined"
     ]
    }
   ],
   "source": [
    "bnm = \"ad_sn\"\n",
    "obj = array_dict[bnm]  # assuming array_dict is your metadata-rich dictionary\n",
    "\n",
    "save_csv(bnm, obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc12ec-49d4-49b2-a097-21f16321bb35",
   "metadata": {},
   "source": [
    "##### calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29828231-f14e-4087-8f95-9819989cbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load array from f\"{bnm}.csv\" in REPO  to a array_dict of name \"bnm\" in memory\n",
    "bnm =\"ad_sn\"                                # copy and paste \"bnm test \" to be name of final result in memory\n",
    "#df, ad_sn = load_csv_to_dict(bnm)  # Load original\n",
    "#df,ad_sn  \n",
    "ad_sn = load_csv_to_dict(bnm)  # Load original# test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4238c-4b12-478f-b1f0-578e1c6bb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fb3ec-55f7-4633-940a-af2b1a99b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a value in dct\n",
    "obj = ad_sn\n",
    "dvt_key = 45863\n",
    "col_name = \"s002\"\n",
    "value = 12\n",
    "set_col_value(obj, dvt_key, col_name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a51b2-1511-4ead-9084-6c4ef2625b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d58fe1-2743-4ef2-88bf-28170833603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to  # def to save pkl from \"\"\"bnm\"\"\"\"\" [SELECTS THE PATH AND FILE NAME]\n",
    "bnm =\"ad_sn\"\n",
    "(load_pickle(bnm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12ea36-864e-4811-800a-37e5ac967fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360e644-1b3e-43cf-973e-ea5c0c051ad3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bnm = \"name\"\n",
    "name = load_pickle(bnm)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c50452-0131-4bd0-8ad6-43c8236970da",
   "metadata": {},
   "source": [
    "##### defs/calls >>> set_col_value(obj, dvt_key, col_name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c597b02-9d97-4fbb-abca-14f99ea1113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a value in a specific item\n",
    "def set_col_value(obj, dvt_key, col_name, value):\n",
    "    try:\n",
    "        idx = obj['dvt'].index(str(dvt_key))\n",
    "        obj[col_name][idx] = value\n",
    "        print(idx)\n",
    "    except ValueError:\n",
    "        print(f\"dvt {dvt_key} not found.\")\n",
    "    except KeyError:\n",
    "        print(f\"Column {col_name} not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998dfc5-f415-4c86-8c28-9502e5d8bba8",
   "metadata": {},
   "source": [
    "#### pkl load/save  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558d70f-f05f-4a38-b0c0-b4cf4b7fcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copilot page\n",
    "def save_pickle(obj, path):\n",
    "    \"\"\"Save object to Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"Load object from Pickle file.\"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6339f27-afdd-4267-b627-d65710d48753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle load call\n",
    "path = \"data/bnm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65c2fe-5fd2-45c0-b526-ac63499130c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle save call\n",
    "path = \"data/bnm\"\n",
    "obj = \"bnm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8bab7-13cf-45e0-9f8e-979f3b04e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl load/save\n",
    "def save_pkl(bnm, array_dict):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "731e2fe7-5236-42c3-a929-5111aa1bf382",
   "metadata": {},
   "source": [
    "# suspected duolicat\n",
    "bnm =\"adsn\"\n",
    "df, adsn =load_csv_to_dict(bnm)\n",
    "print(\"df & are temp names  and need to re named realt\")\n",
    "df\n",
    "#adsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747e09f-fa44-4f18-bdf0-c8bdae37f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    path_pkl = Path(\"REPO/data\") / f\"{bnm}.pkl\"\n",
    "\n",
    "    # Save updated dictionary back to Pickle\n",
    "    with open(path_pkl, 'wb') as f:\n",
    "        pickle.dump(array_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfec26-c921-48b7-abb2-495f58f59ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Load Pickle file, apply edits to array_dict, and overwrite original file.\n",
    "    Assumes file is stored in REPO/data/{bnm}.pkl\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f386168-f659-46a1-894a-ad7ba9b1978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original Pickle\n",
    "with open(\"REPO/data/my_data.pkl\", 'rb') as f:\n",
    "    array_dict = pickle.load(f)\n",
    "\n",
    "# ... perform edits to array_dict ...\n",
    "\n",
    "# Save back to same Pickle file\n",
    "load_edit_save_pkl(\"my_data\", array_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009432b5-1c99-49d7-b45b-4d431e4b734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnm = \"ad_sn\"\n",
    "array_dict = \"ad_sn\"\n",
    "load_edit_save_pkl(bnm, array_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dee0180a-3ec9-420d-8195-4f15cf92e285",
   "metadata": {},
   "source": [
    "# end ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ac38f-dd84-4bf5-bf21-cfae1ef6bd69",
   "metadata": {},
   "source": [
    "# **02_array_dict_builder.py**   |  *Transform arrays into array_dict with metadata*\n",
    "_ ***Script Update for Data Dictionary Creation** link *https://copilot.microsoft.com/shares/pages/jLLrDDP9aZqQjatwkyFfr*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb8ff7-8caf-4029-896e-5fc56b38b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and isolate the raw headers from \"xl_ad_sn_hdr,csl\"\n",
    "# Load CSV\n",
    "\n",
    "\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Inspect raw headers\n",
    "raw_headers = df.columns.tolist()\n",
    "#print(\"Raw headers:\", raw_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977397a-44e3-406b-af83-5dc193a83366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Full Setup >> headers >> dtv_index >> array_dict\n",
    "csv_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/xl_ad_sn.csv\")\n",
    "df = pd.read_csv(csv_path)         # read array from \"csv_path\"\n",
    "\n",
    "# Extract headers and data\n",
    "headers = df.columns.tolist()\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "# Locate the index of the 'dtv' column\n",
    "dtv_index = headers.index('dtv')\n",
    "\n",
    "# Build array_dict\n",
    "array_dict = {}\n",
    "\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928214d4-84af-473c-a5dc-2399342ff359",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 🧪 Verify the construction\n",
    "\n",
    "for dtv, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DTV: {dtv}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a91b41-4db5-4c9d-aabc-806c4b3210d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Continue Building array_dict\n",
    "xl_ad_sn = df.to_numpy()\n",
    "\n",
    "array_dict = {}\n",
    "for row in xl_ad_sn:\n",
    "    dtv_key = row[dtv_index]\n",
    "    raw_values = np.delete(row, dtv_index)\n",
    "\n",
    "    array_dict[dtv_key] = {\n",
    "        'raw_values': raw_values.tolist(),\n",
    "        'flags': {},\n",
    "        'attributes': {\n",
    "            'features': [h for i, h in enumerate(raw_headers) if i != dtv_index]\n",
    "        },\n",
    "        'classification': {}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a6b3c-3baf-4d77-a632-e4e0f3d7502b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for dvt, entry in list(array_dict.items())[:3]:\n",
    "    print(f\"DVT: {dvt}\")\n",
    "    print(\"Raw:\", entry['raw_values'])\n",
    "    print(\"Features:\", entry['attributes']['features'])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f33a7-965a-48dc-a670-10dfebc56ad2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 03 Setting the classification of \"dat_col\"s with attribts stored in files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1be936-396b-470c-8f53-adf7c0b884fc",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacebebe-f719-4569-bf24-f8e13493c97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Metadata Injection Function in Python**\n",
    "_\n",
    "*https://copilot.microsoft.com/shares/pages/LpNfiWnk3ndWRko9EnfxS*\n",
    "\n",
    "_Question *I would like like to have function that would accept a \"dat_col_sn\" and and a \"attribut_sn\" and read the \"value\" in that item in the file \"attrbts_sn_x_dat_col_sn\" and set that \"attribute\" in that \"dat_col\" to that \"value\". If the class & attrbute did not exist, it would create one. Js that possible.*\n",
    "\n",
    "Absolutely, Bill—that’s not only possible, it’s a great example of modular, operator-driven metadata injection. You’re describing a function that:\n",
    "\n",
    "Accepts a dat_col_sn (e.g. 's003') and an attribute_sn (e.g. 'a001')\n",
    "\n",
    "Looks up the value at that coordinate in a matrix file (e.g. CSV or Excel)\n",
    "\n",
    "Injects that value into the corresponding array_dict[dat_col_sn]['attributes'][attribute_sn]\n",
    "\n",
    "Creates the attribute if it doesn’t exist\n",
    "\n",
    "Let’s scaffold that cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00a24f-c55c-4746-b2a3-8e36c11f0c8a",
   "metadata": {},
   "source": [
    "## 🧠 Function: inject_attribute_from_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4da89-e8e1-4563-b31d-42123ae0a2dd",
   "metadata": {},
   "source": [
    "### 🔹 Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc222d44-63c7-486b-8b31-199d3c8cb2fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. The matrix file is named \"attrbts_sn_x_dat_col_sn.csv\" ..................ok  [matrix_path]\n",
    "2. Rows = attribute_sn (e.g. 'a000', 'a001')................................ok\n",
    "3. Columns = dat_col_sn (e.g. 's000', 's001')...............................ok\n",
    "4. You’ve already built array_dict keyed by dat_col_sn.........need to load ##\n",
    "\"\\\\wsl.localhost\\Ubuntu\\home\\bhuns\\JL_1\\data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "r\"data\\attrbts_sn_x_dat_col_sn.csv\"\n",
    "\"attrbts_sn_x_dat_col_sn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5697a9a-c574-4078-9f7c-1f59ef049dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"attrbts_sn_x_dat_col_sn.csv\"\n",
    "df = read_wsl_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4ff18-12c1-4e6c-8760-a0d350f6203e",
   "metadata": {},
   "source": [
    "### 🛠️ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d282555-ebff-4634-9265-f243e0e69cda",
   "metadata": {},
   "source": [
    "#### inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822aaf6-b7cb-4915-9f47-23f759e540bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "\n",
    "def inject_attribute_from_matrix(array_dict, dat_col_sn, attribute_sn, matrix_path):\n",
    "    # Load matrix\n",
    "    df = pd.read_csv(matrix_path, index_col=0)  # Assumes first column is attribute_sn\n",
    "\n",
    "    # Validate existence\n",
    "    if attribute_sn not in df.index:\n",
    "        raise ValueError(f\"Attribute '{attribute_sn}' not found in matrix rows.\")\n",
    "    if dat_col_sn not in df.columns:\n",
    "        raise ValueError(f\"Data column '{dat_col_sn}' not found in matrix columns.\")\n",
    "\n",
    "    # Extract value\n",
    "    value = df.at[attribute_sn, dat_col_sn]\n",
    "\n",
    "    # Inject into array_dict\n",
    "    if dat_col_sn not in array_dict:\n",
    "        raise KeyError(f\"Data column '{dat_col_sn}' not found in array_dict.\")\n",
    "\n",
    "    entry = array_dict[dat_col_sn]\n",
    "    if 'attributes' not in entry:\n",
    "        entry['attributes'] = {}\n",
    "\n",
    "    entry['attributes'][attribute_sn] = value\n",
    "\n",
    "    return value  # Optional: return for confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72aaad-bc23-4809-87f1-21e7f7b5a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🧪 Example Usage\n",
    "matrix_path = os.path.join(os.path.expanduser(\"~\"), \"JL_1/data/attrbts_sn_x_dat_col_sn.csv\")\n",
    "value = inject_attribute_from_matrix(array_dict, 's003', 'a001', matrix_path)\n",
    "\n",
    "print(f\"Injected value: {value}\")\n",
    "print(array_dict['s003']['attributes']['a001'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92183b-390b-4102-abe4-26f1fd701bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 🔍 Optional Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b019af2-6819-4602-95e7-a49ccdc9d8d6",
   "metadata": {},
   "source": [
    "Add logging or provenance tags\n",
    "\n",
    "Support batch injection for all attributes or all columns\n",
    "\n",
    "Validate types or ranges before injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f05d5-f155-4ff5-8d9e-7bc4a3b4f885",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0489f-7e62-4302-a7d9-408d6294530d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa619ee3-c338-4249-9d6c-9e391a584836",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6236d-e13d-4968-8c9a-d9c24598624e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3906b6-b0b1-4858-bd06-e6684dac4c36",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39df37d-95c7-4f9c-91bd-c1eb34ee2aad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81456798-0e17-428d-801a-171eed22c9f8",
   "metadata": {},
   "source": [
    "### next###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c18f0-484b-48e4-a843-582ec26cd54c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### next####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c5dfb-6795-47ed-be00-c950416bf641",
   "metadata": {},
   "source": [
    "# **05_storage_utils.py**  |  *Save/load using Pickle, Excel, HDF5*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be694f8-e508-4ad8-9e79-024d0ba2e7a1",
   "metadata": {},
   "source": [
    "# **04_gui_selector.py**  |  *Operator-driven GUI for selecting and grouping entries*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d2ff6-add0-449c-932d-96d117f241e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **0?_classification_registry.py**  |  *Define classification args, flags, and validation logic*\n",
    "_***Wrking but funct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707113e-7e27-414f-9c6e-a89fcfe1e908",
   "metadata": {},
   "source": [
    "**Classification Registry Implementation** \n",
    "_ *https://copilot.microsoft.com/shares/pages/P91viiY6QzR3Mp4WUnbFf*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375551f-c4a6-4ad2-8526-15cbe23d5b7f",
   "metadata": {},
   "source": [
    "## 🧠 Classification Registry Scaffold (classification_registry.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86b3d7-94b9-4fca-93c1-79cf5d508ecd",
   "metadata": {},
   "source": [
    "### Perfect, Bill. You’ve got a classification matrix scaffolded—rows as attribute_sn (e.g. a000, a001, ...) and columns as dat_col.sn (e.g. s000, s001, ...). \n",
    "1. That’s a great foundation for a modular classification registry.\n",
    "2. Let’s build a separate file—say, classification_registry.py—that can:\n",
    "3. Load and validate the matrix\n",
    "4. Apply classification logic per attribute or per column\n",
    "5. Track provenance and confidence\n",
    "6. Return structured results for embedding into array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54d75e-5f66-43af-8beb-58aba94c6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔹 1. Load the Matrix\n",
    "\n",
    "def load_classification_matrix(path):\n",
    "    df = pd.read_csv(path)  # or pd.read_excel\n",
    "    df.index.name = 'attribute_sn'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce72b28-ce58-45f4-8d33-d3bdd00ebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 2. Define Classification Methods\n",
    "def threshold_classifier(row, threshold=0.5):\n",
    "    score = row.mean()\n",
    "    group = 'A' if score > threshold else 'B'\n",
    "    confidence = round(abs(score - threshold), 3)\n",
    "    return group, confidence\n",
    "\n",
    "def zscore_classifier(row):\n",
    "    z = (row - row.mean()) / row.std()\n",
    "    group = 'High' if z.mean() > 1 else 'Low'\n",
    "    confidence = round(z.std(), 3)\n",
    "    return group, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b28ab-7945-4558-aa05-f36a1d3fee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 3. Registry Dictionary\n",
    "classification_registry = {\n",
    "    'threshold': threshold_classifier,\n",
    "    'zscore': zscore_classifier\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d72b2-20cf-4858-a991-c42bda18fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 4. Apply Classification\n",
    "def classify_matrix(df, method='threshold'):\n",
    "    results = {}\n",
    "    classifier = classification_registry[method]\n",
    "\n",
    "    for attr_sn, row in df.iterrows():\n",
    "        group, confidence = classifier(row)\n",
    "        results[attr_sn] = {\n",
    "            'group': group,\n",
    "            'confidence': confidence,\n",
    "            'method': method\n",
    "        }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d34f0d-0b83-4ef9-8479-e9ed5446305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 5. Embed into array_dict\n",
    "def embed_classification(array_dict, classification_results):\n",
    "    for dvt_key, result in classification_results.items():\n",
    "        if dvt_key in array_dict:\n",
    "            array_dict[dvt_key]['classification'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e463b-3c83-4b35-86c2-3f52cc57ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 Optional Diagnostic\n",
    "def preview_classification(results, n=5):\n",
    "    for k in list(results.keys())[:n]:\n",
    "        print(f\"{k}: {results[k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3bd86-41c3-4c8c-bc86-ea7675266348",
   "metadata": {},
   "source": [
    "# **06_diagnostics.py**  |  *Overlay tools for inspecting metadata and classification*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b615ff5-4b49-43cd-a5b4-92ec00aa9a16",
   "metadata": {},
   "source": [
    "# **07_tests.py**  |  *Reproducible test cases and versioning checks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d60fd-80ed-4657-9988-1441f4bad47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0ebc9-cada-4730-a364-8700fa6a67d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
