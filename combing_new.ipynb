{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65339162-459e-42b3-a6c4-b1c4bfa0f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106c569-a66b-4fed-a7b7-08aa0af8cd69",
   "metadata": {},
   "source": [
    "# Create array_dict from an array in a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f65a25-9d74-43c9-87ae-4ac6f5fe03c1",
   "metadata": {},
   "source": [
    "## Read the file with protection from oddball encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47bee77-7048-4736-997f-f76057630da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_csv_read(filename, usecols=None, index_col=None):\n",
    "    ## Read the file with protection from oddball encoders.\n",
    "    try:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col, encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64309361-6a42-4321-a571-30e9b7ae324b",
   "metadata": {},
   "source": [
    "## *Load* ***array_dict*** *using* ***safe_csv_read()*** *set index,convert data list to np.arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c588aa-6125-40e8-b5ae-406242da3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group_arrays(filename: str, group_name: str, grp_list: list[str], index_col: str = \"dtv\") -> dict[str, np.ndarray]:\n",
    "    ## *Load the array using* ***safe_csv_read()*** *set index,convert data list to np.arrays & build* ***array_dict***\n",
    "    \n",
    "    columns_to_load = [index_col] + grp_list\n",
    "    df = safe_csv_read(filename, usecols=columns_to_load)\n",
    "    # before safe_csv_read df = pd.read_csv(filename, usecols=columns_to_load, encoding=encoding)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "\n",
    "    array_dict = {f\"{group_name}_{col}\": df[col].to_numpy() for col in grp_list}\n",
    "    array_dict[f\"{group_name}_{index_col}\"] = df.index.to_numpy()  # include index as array\n",
    "    return array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105af2b-2adb-4cdb-b5e1-04647459ec90",
   "metadata": {},
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05204e34-da7b-4e76-96bc-9e66cd3a31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***\n",
    "filename = \"xl_dtv_all_snm_tst.csv\"\n",
    "group_name = \"grp_tst\"\n",
    "grp_list =[\"Eliquist\",\"Magtien\"]\n",
    "# before group array   array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"DATE_V\", encoding = \"ISO-8859-1\")\n",
    "array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"dtv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e5a28e-f743-4ac3-87d0-959e42d46a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1., nan, nan]),\n",
       " 'grp_tst_Magtien': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan, nan]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858, 45859, 45860])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81fc835-e1f9-4bac-ad22-a8f4baab4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(45854)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict['grp_tst_dtv'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abeb0f3a-e5a7-430b-9fc5-972cc5522be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict['grp_tst_Magtien'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f844d6-a1cb-41be-a119-b3b2d1dd5cdf",
   "metadata": {},
   "source": [
    "## *From a ***dtv*** find* ***row_index*** *for a ***specific dtv*** *then use* ***row_index()*** *to find the value in a given dat_col np.array to get the* ***datcol_value*** for that ***specific dtv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a056a-957d-43c4-b018-747203613e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the array using safe_csv_read() \n",
    "# set index,convert data list to np.arrays & build array_dict\n",
    "dtv_array = array_dict[\"grp_tst_dtv\"]\n",
    "grp_tst_dtv = 45852\n",
    "\n",
    "# Find the index position\n",
    "row_index = np.where(dtv_array == grp_tst_dtv)[0]\n",
    "\n",
    "if row_index.size > 0:\n",
    "    print(f\"✅ row_index for {grp_tst_dtv}: {row_index[0]}\")\n",
    "else:\n",
    "    print(f\"⚠️ Date {grp_tst_dtv} not found in 'grp_tst_dtv'\")\n",
    "# print(\"row_index  =  \",row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc36084-142c-4c00-aa52-b2e0aabafcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_dict['grp_tst_Magtien'][row_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ef307-e1f4-434b-8187-aee9d869d7d7",
   "metadata": {},
   "source": [
    "# Manual Input to array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd134bd-607f-496c-a661-260ae7aeac18",
   "metadata": {},
   "source": [
    "## BASIC SIMPLWE INPUT FUNCTION *** does not save entries yet*** Interactive Data Entry Function [not addapted from copilot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b268f49a-0bbe-4321-8c5e-4d22405a24cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1., nan, nan]),\n",
       " 'grp_tst_Magtien': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan, nan]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858, 45859, 45860])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict           # non essentual readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2b862f-0193-4442-b238-abd47d8cbd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_data_values_dtv(array_dict: dict, group_name: str, col_list: list[str], index_key: str = \"dtv\") -> None:\n",
    "    #     # def to load values of doses for a given \"dtv\"\n",
    "    # Get master index\n",
    "    master_index = array_dict.get(f\"{group_name}_{index_key}\")\n",
    "    if master_index is None:\n",
    "        raise KeyError(f\"❌ Master index '{group_name}_{index_key}' not found in array_dict.\")\n",
    "\n",
    "    # Loop until valid dtv or abort\n",
    "    while True:\n",
    "        try:\n",
    "            dtv_input = int(input(\"📅 Enter the date (format: NNNNN): \").strip())\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid format. Please enter a numeric date.\")\n",
    "            continue\n",
    "\n",
    "        if dtv_input in master_index:\n",
    "            break  # valid date, proceed\n",
    "        else:\n",
    "            choice = input(f\"⚠️ '{dtv_input}' not found in timeline. Re-enter (r) or Abort (a)? \").strip().lower()\n",
    "            if choice == \"a\":\n",
    "                print(\"🚫 Entry aborted.\")\n",
    "                return\n",
    "\n",
    "    # Collect values interactively\n",
    "    new_values = {}\n",
    "    for col in col_list:\n",
    "        val = input(f\"🔢 Enter value for '{col}': \").strip()\n",
    "        try:\n",
    "            new_values[col] = float(val)\n",
    "        except ValueError:\n",
    "            new_values[col] = np.nan  # fallback if input is invalid\n",
    "\n",
    "    # Create new DataFrame with dtv index\n",
    "    df_new = pd.DataFrame(new_values, index=[dtv_input])\n",
    "    df_new.index.name = index_key\n",
    "\n",
    "    # Reindex to match master timeline\n",
    "    df_new = df_new.reindex(master_index)\n",
    "\n",
    "    # Append each column to array_dict\n",
    "    for col in col_list:\n",
    "        key = f\"{group_name}_{col}\"\n",
    "        array_dict[key] = df_new[col].to_numpy()\n",
    "        print(f\"✅ Updated '{key}' with new entry for {dtv_input}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1de04fc-0c17-4e1d-a28f-05b2fd7c729c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# CALL >>  \"enter_data_values_dtv(): to load values of doses for a given \"dtv\"\n",
    "group_name = \"grp_tst\"\n",
    "col_list = [\"Eliquist\", \"Magtien\", \"GPLC\"]\n",
    "enter_data_values_dtv(array_dict, group_name, col_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb56156-99e7-4ffe-a1b6-ed3191405828",
   "metadata": {},
   "source": [
    "## CLASSES AND SKIPS ADDED***  does not save entries yet*** Interactive Data Entry Function   [not INTEGRATED  from copilot]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a7af3-bc0c-4b08-9183-940557521c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### ###########Question to copipol###################\n",
    "Yesterday you help build the follow in input function and it is working fine. ======================================= def enter_data_values_dtv(array_dict: dict, group_name: str, col_list: list[str], index_key: str = \"dtv\") -> None: # # def to load values of doses for a given \"dtv\" # Get master index master_index = array_dict.get(f\"{group_name}{index_key}\") if master_index is None: raise KeyError(f\"❌ Master index '{group_name}{index_key}' not found in array_dict.\") # Loop until valid dtv or abort while True: try: dtv_input = int(input(\"📅 Enter the date (format: NNNNN): \").strip()) except ValueError: print(\"❌ Invalid format. Please enter a numeric date.\") continue if dtv_input in master_index: break # valid date, proceed else: choice = input(f\"⚠️ '{dtv_input}' not found in timeline. Re-enter (r) or Abort (a)? \").strip().lower() if choice == \"a\": print(\"🚫 Entry aborted.\") return # Collect values interactively new_values = {} for col in col_list: val = input(f\"🔢 Enter value for '{col}': \").strip() try: new_values[col] = float(val) except ValueError: new_values[col] = np.nan # fallback if input is invalid # Create new DataFrame with dtv index df_new = pd.DataFrame(new_values, index=[dtv_input]) df_new.index.name = index_key # Reindex to match master timeline df_new = df_new.reindex(master_index) # Append each column to array_dict for col in col_list: key = f\"{group_name}_{col}\" array_dict[key] = df_new[col].to_numpy() print(f\"✅ Updated '{key}' with new entry for {dtv_input}\") ==========call ============================ group_name = \"grp_tst\" col_list = [\"Eliquist\", \"Magtien\", \"GPLC\"] enter_data_values_dtv(array_dict, group_name, col_list) ============================================== I would like modify our this function to include classes . These are the following steps The input function that accepts a \"dtv\" , sets the row in a data_dict and enters enter value in each dat_col. [unchanged] adding classes ------------------ Each \"dat_col\" belongs to a \"supplement class\" attribute = name[3bits] attribute = mrn_dose[3bits] attribute = default_mrn_dose[3bits] attribute = value[list for all rows] filled_flag = [1bit] active_flag =[1bit] the row = dvt[integer] the function will loop through ) if the \"(dat_col.active_flag \" = false or the \": \"dat_col.filled_flag \" = true. it moves on to the next \"dat_col when finding a col that meets the conditions for entry------------- it displays the :dat_col.name & dat_col,mrn_dose & dat_col.default_mrn_dose & the \"dtv\" If I hit \"enter\" , I set \"dat_col,mrn_dose.value[dtv] is set to dat_col.default_mrn_dose then it sets \" \"dat_col.filled_flag \" = true, and moves on to next \"dat_col\" If I hit the \"right arrow\" it just sets the \"dat_col.filled_flag \" = true, and moves on to next \"dat_col\" Until it completes all dat_col.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58783750-e0e3-4e39-9200-14dcdca30c2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Define the Supplement Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef24e4-ccc4-4d4a-8595-cffc23eaab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supplement:\n",
    "    def __init__(self, name: str, default_mrn_dose: float, timeline: list[int]):\n",
    "        self.name = name[:3]  # 3-bit name\n",
    "        self.mrn_dose = [np.nan] * len(timeline)  # 3-bit dose list\n",
    "        self.default_mrn_dose = default_mrn_dose  # 3-bit default\n",
    "        self.value = [np.nan] * len(timeline)  # full timeline values\n",
    "        self.filled_flag = False  # 1-bit\n",
    "        self.active_flag = True   # 1-bit\n",
    "        self.timeline = timeline  # reference for indexing\n",
    "\n",
    "    def set_value(self, dtv: int, val: float):\n",
    "        try:\n",
    "            idx = self.timeline.index(dtv)\n",
    "            self.value[idx] = val\n",
    "            self.mrn_dose[idx] = val\n",
    "            self.filled_flag = True\n",
    "        except ValueError:\n",
    "            print(f\"❌ DTV {dtv} not found in timeline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb73ff2-2098-4b91-ac36-97d90462bb93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Refactor the Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee0a39-e6ee-4ce8-ad8a-b321b63d4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_supplement_values(supplements: list[Supplement], dtv: int) -> None:\n",
    "    for supp in supplements:\n",
    "        if not supp.active_flag or supp.filled_flag:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🧾 Supplement: {supp.name}\")\n",
    "        print(f\"💊 Default Dose: {supp.default_mrn_dose}\")\n",
    "        print(f\"📅 Date: {dtv}\")\n",
    "\n",
    "        user_input = input(\"⏎ Enter to accept default, → to skip, or type dose: \").strip()\n",
    "\n",
    "        if user_input == \"\":\n",
    "            supp.set_value(dtv, supp.default_mrn_dose)\n",
    "            print(f\"✅ Set to default: {supp.default_mrn_dose}\")\n",
    "        elif user_input == \"→\":\n",
    "            supp.filled_flag = True\n",
    "            print(\"➡️ Skipped.\")\n",
    "        else:\n",
    "            try:\n",
    "                dose = float(user_input)\n",
    "                supp.set_value(dtv, dose)\n",
    "                print(f\"✅ Set to entered dose: {dose}\")\n",
    "            except ValueError:\n",
    "                print(\"❌ Invalid input. Skipping.\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e280d9-80cb-4312-bebe-2358d5aa0cf4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Integrate with Timeline and Array Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c61bd-8d1a-495c-aa13-3e538da311b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_supplement_entry(array_dict: dict, group_name: str, supplement_defs: dict[str, float], index_key: str = \"dtv\") -> None:\n",
    "    master_index = array_dict.get(f\"{group_name}{index_key}\")\n",
    "    if master_index is None:\n",
    "        raise KeyError(f\"❌ Master index '{group_name}{index_key}' not found in array_dict.\")\n",
    "\n",
    "    # Get valid DTV\n",
    "    while True:\n",
    "        try:\n",
    "            dtv_input = int(input(\"📅 Enter the date (format: NNNNN): \").strip())\n",
    "        except ValueError:\n",
    "            print(\"❌ Invalid format. Please enter a numeric date.\")\n",
    "            continue\n",
    "\n",
    "        if dtv_input in master_index:\n",
    "            break\n",
    "        else:\n",
    "            choice = input(f\"⚠️ '{dtv_input}' not found. Re-enter (r) or Abort (a)? \").strip().lower()\n",
    "            if choice == \"a\":\n",
    "                print(\"🚫 Entry aborted.\")\n",
    "                return\n",
    "\n",
    "    # Create Supplement objects\n",
    "    supplements = [Supplement(name, default, master_index) for name, default in supplement_defs.items()]\n",
    "\n",
    "    # Run entry loop\n",
    "    enter_supplement_values(supplements, dtv_input)\n",
    "\n",
    "    # Update array_dict\n",
    "    for supp in supplements:\n",
    "        key = f\"{group_name}_{supp.name}\"\n",
    "        array_dict[key] = supp.value\n",
    "        print(f\"📦 Stored '{key}' in array_dict.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ea083-495f-462e-8cc3-22cb317885d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ✅ Example Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23222c79-3489-4f23-aff9-cfabaea15d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplement_defs = {\n",
    "    \"Eliquist\": 5.0,\n",
    "    \"Magtien\": 2.0,\n",
    "    \"GPLC\": 3.5\n",
    "}\n",
    "\n",
    "run_supplement_entry(array_dict, \"grp_tst\", supplement_defs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c2861-7ef4-43ee-a9c9-d63f4f0df760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SAVE DATA UPDATES FROM ***array_dict*** TO XLFILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a1de5a-92d4-49fd-99a5-fb1215147cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 60.]),\n",
       " 'grp_tst_Magtien': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 30.]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858, 45859, 45860]),\n",
       " 'grp_tst_GPLC': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 21.])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict            # non essentual readout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b7e38-f34c-4391-8e64-a64c9d436345",
   "metadata": {},
   "source": [
    "## 45858 Add a new column [not addapted from copilot]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d6e0a-b037-423e-913c-f0dbab7803fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Start of setting up classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04a4f8-63b8-4d6b-93ba-f885f3884539",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## -Oriented DataCObjectolumn Design in Python\n",
    "https://copilot.microsoft.com/shares/pages/MZyaioewJp2wR4mSwfShP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96db62-b2a3-443e-8426-c8072118da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesGroup:\n",
    "    def __init__(self, filename: str, group_name: str, columns: list[str], index_col: str = \"DATE_V\", encoding: str = \"ISO-8859-1\"):\n",
    "        self.group_name = group_name\n",
    "        self.index_col = index_col\n",
    "        self.filename = filename\n",
    "        self.encoding = encoding\n",
    "        self.columns = columns\n",
    "        self.array_dict = {}\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        cols_to_load = [self.index_col] + self.columns\n",
    "        df = pd.read_csv(self.filename, usecols=cols_to_load, encoding=self.encoding)\n",
    "        df.set_index(self.index_col, inplace=True)\n",
    "\n",
    "        # Store index as array\n",
    "        self.array_dict[f\"{self.group_name}_{self.index_col}\"] = df.index.to_numpy()\n",
    "\n",
    "        # Store each column as array\n",
    "        for col in self.columns:\n",
    "            arr = df[col].to_numpy()\n",
    "            self.array_dict[f\"{self.group_name}_{col}\"] = arr\n",
    "\n",
    "    def get_array(self, name: str) -> np.ndarray:\n",
    "        return self.array_dict.get(name)\n",
    "\n",
    "    def summary(self):\n",
    "        print(f\"📦 Group: {self.group_name}\")\n",
    "        for key, arr in self.array_dict.items():\n",
    "            print(f\"  {key}: shape={arr.shape}, dtype={arr.dtype}, nulls={np.isnan(arr).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc4f68-0b42-40c4-bfa3-08be7f66cd80",
   "metadata": {},
   "source": [
    "## Using doses in classis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2fe0ef-856f-4db8-a52a-c6d89bd45b46",
   "metadata": {},
   "source": [
    "***Python Class for Supplement Dosage Modeling***\n",
    "https://copilot.microsoft.com/shares/pages/TWp5or9jyx8bJtPj5cGfv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32641eae-1c4e-41a4-876d-4e676075a42f",
   "metadata": {},
   "source": [
    "You can definitely model ***actual_dose*** and ***default_dose*** as ***3-bit integers (values 0–7)***, and multiply them by a gr_per_dose scalar to compute the effective dosage in grams. Python doesn’t have a native 3-bit dtype, but you can enforce the constraint and optimize storage using NumPy or bit masking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5f41e-27d6-475d-982c-30752ed6e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Supplement:\n",
    "    def __init__(self, name, gr_per_dose, default_dose=1, actual_dose=None):\n",
    "        self.name = name\n",
    "        self.gr_per_dose = gr_per_dose  # grams per dose unit\n",
    "        self.default_dose = self._validate_dose(default_dose)\n",
    "        self.actual_dose = self._validate_dose(actual_dose) if actual_dose is not None else self.default_dose\n",
    "\n",
    "    def _validate_dose(self, dose):\n",
    "        # Enforce 3-bit constraint (0–7)\n",
    "        if not (0 <= dose <= 7):\n",
    "            raise ValueError(f\"Dose must be between 0 and 7 (3-bit range). Got: {dose}\")\n",
    "        return np.uint8(dose)  # Efficient storage\n",
    "\n",
    "    @property\n",
    "    def effective_dose_grams(self):\n",
    "        return self.actual_dose * self.gr_per_dose\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"{self.name}: {self.actual_dose} dose units × {self.gr_per_dose} g/unit = \"\n",
    "                f\"{self.effective_dose_grams:.2f} g total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d459b-6a53-48eb-b6fa-caa00c7c67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Example Usage\n",
    "vitamin_c = Supplement(name=\"Vitamin C\", gr_per_dose=0.5, default_dose=2)\n",
    "print(vitamin_c)  # Output: Vitamin C: 2 dose units × 0.5 g/unit = 1.00 g total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262970e-f5f5-4730-9a55-2d1262d676b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Discriptions of ***array_dict***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965a8b8-122a-4c08-b4de-ed3f6a975cdf",
   "metadata": {},
   "source": [
    "***array_dict*** Is a working dictionary where  dtv is the index and selected dat_cols which are np.arrays\n",
    "1. dtv is a col of integers representing the number of days since jan 1 1900 and ends with today.\n",
    "2. dtv is used as the index for all dat_cols\n",
    "3. all dat_cols have cls attributes common to all the values in that dat-col\n",
    "5. all dat_cols have cls methods that instructions to certain statistics of the dat_col values.\n",
    "6. dat_col attributes and methods are read by a . behind dat_col ie dat_col.method or attribute. ***see*** *https://copilot.microsoft.com/shares/pages/MZyaioewJp2wR4mSwfShP* for examples.\n",
    "7. all have same length as the ***dtv col*** and are stored in a ***xl csv file array*** with ***\"dtv\"*** as the first col and str headers as the first row.\n",
    "8. ***array_dict*** use the ***dtv*** as index so that every row has a ***row_index***\n",
    "9. The ***row_index*** for a ***specific dtv*** is computed and it is used to find the value of ***dat_col*** for that date.  \n",
    "10. ***Time Alignment*** It ensures all arrays—whether supplements, motion, or biochemical—are synchronized to the same timeline. That’s essential for cross-correlation, lag analysis, and time-shifting.\n",
    "11. Plotting & Visualization You’ll need dtv as the x-axis for any time-series plots. Without it, your arrays are just floating sequences.\n",
    "12. Diagnostics & Gaps You can detect missing data, irregular sampling, or temporal drift by comparing ***\"dtv\"*** across groups.\n",
    "13. Batch Operations If you’re merging arrays from different domains (e.g., Motion, Supplements, Sleep), having a shared **\"dtv\"*** lets you align them cleanly—even if some arrays are sparse.\n",
    ".................array_dict[f\"{group_name}_dtv] = df.index.to_numpy()\n",
    "---------------------------------------------------------------------\n",
    "{\n",
    "    \"grp_tst_dtv\": np.array([...]),\n",
    "    \"grp_tst_Eliquist\": np.array([...]),\n",
    "    \"grp_tst_Magtien\": np.array([...]),\n",
    "    \"grp_tst_GPLC\": np.array([...])\n",
    "}\n",
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d5866-e45b-4f1e-b178-38a0e469e16a",
   "metadata": {},
   "source": [
    "***Let’s scaffold a clean, modular TimeSeriesGroup class that fits your architecture and handles:***\n",
    "\n",
    "✅ Selective column loading from a master CSV\n",
    "\n",
    "✅ Index alignment via DATE_V\n",
    "\n",
    "✅ Dictionary-style access to NumPy arrays\n",
    "\n",
    "✅ Metadata logging for diagnostics and traceability"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8b81c9b-6e43-403e-ac6f-5b5800557c20",
   "metadata": {},
   "source": [
    "print(\"bill\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
