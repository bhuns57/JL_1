{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65339162-459e-42b3-a6c4-b1c4bfa0f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106c569-a66b-4fed-a7b7-08aa0af8cd69",
   "metadata": {},
   "source": [
    "# Create array_dict from an array in a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f65a25-9d74-43c9-87ae-4ac6f5fe03c1",
   "metadata": {},
   "source": [
    "## Read the file with protection from oddball encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b47bee77-7048-4736-997f-f76057630da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_csv_read(filename, usecols=None, index_col=None):\n",
    "    ## Read the file with protection from oddball encoders.\n",
    "    try:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col, encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64309361-6a42-4321-a571-30e9b7ae324b",
   "metadata": {},
   "source": [
    "## *Load the array using* ***safe_csv_read()*** *set index,convert data list to np.arrays & build* ***array_dict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c588aa-6125-40e8-b5ae-406242da3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group_arrays(filename: str, group_name: str, grp_list: list[str], index_col: str = \"dtv\") -> dict[str, np.ndarray]:\n",
    "    ## *Load the array using* ***safe_csv_read()*** *set index,convert data list to np.arrays & build* ***array_dict***\n",
    "    \n",
    "    columns_to_load = [index_col] + grp_list\n",
    "    df = safe_csv_read(filename, usecols=columns_to_load)\n",
    "    # before safe_csv_read df = pd.read_csv(filename, usecols=columns_to_load, encoding=encoding)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "\n",
    "    array_dict = {f\"{group_name}_{col}\": df[col].to_numpy() for col in grp_list}\n",
    "    array_dict[f\"{group_name}_{index_col}\"] = df.index.to_numpy()  # include index as array\n",
    "    return array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c77a0-b5fd-49d0-9238-94deeecfe941",
   "metadata": {},
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05204e34-da7b-4e76-96bc-9e66cd3a31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***\n",
    "filename = \"xl_dtv_all_snm_tst.csv\"\n",
    "group_name = \"grp_tst\"\n",
    "grp_list =[\"Eliquist\",\"Magtien\"]\n",
    "# before group array   array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"DATE_V\", encoding = \"ISO-8859-1\")\n",
    "array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"dtv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45e5a28e-f743-4ac3-87d0-959e42d46a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([10,  9,  8,  7,  6,  5,  4,  3,  2,  1]),\n",
       " 'grp_tst_Magtien': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f81fc835-e1f9-4bac-ad22-a8f4baab4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(45854)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict['grp_tst_dtv'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abeb0f3a-e5a7-430b-9fc5-972cc5522be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict['grp_tst_Magtien'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e6a056a-957d-43c4-b018-747203613e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row index for 45852: 3\n"
     ]
    }
   ],
   "source": [
    "dtv_array = array_dict[\"grp_tst_dtv\"]\n",
    "grp_tst_dtv = 45852\n",
    "\n",
    "# Find the index position\n",
    "row_index = np.where(dtv_array == grp_tst_dtv)[0]\n",
    "\n",
    "if row_index.size > 0:\n",
    "    print(f\"✅ Row index for {grp_tst_dtv}: {row_index[0]}\")\n",
    "else:\n",
    "    print(f\"⚠️ Date {grp_tst_dtv} not found in 'grp_tst_dtv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cc36084-142c-4c00-aa52-b2e0aabafcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict['grp_tst_Magtien'][row_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262970e-f5f5-4730-9a55-2d1262d676b1",
   "metadata": {},
   "source": [
    "# Discriptions of ***array_dict***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965a8b8-122a-4c08-b4de-ed3f6a975cdf",
   "metadata": {},
   "source": [
    "***array_dict*** Is a working dictionary where  dtv is the index and selected dat_cols which are np.arrays\n",
    "1. dtv is a col of integers representing the number of days since jan 1 1900 and ends with today.\n",
    "2. dtv is used as the index for all dat_cols\n",
    "3. all dat_cols have cls attributes common to all the values in that dat-col\n",
    "5. all dat_cols have cls methods that instructions to certain statistics of the dat_col values.\n",
    "6. dat_col attributes and methods are read by a . behind dat_col ie dat_col.method or attribute. ***see*** *https://copilot.microsoft.com/shares/pages/MZyaioewJp2wR4mSwfShP* for examples.\n",
    "7. all have same length as the ***dtv col*** and are stored in a ***xl csv file array*** with ***\"dtv\"*** as the first col and str headers as the first row.\n",
    "8. ***Time Alignment*** It ensures all arrays—whether supplements, motion, or biochemical—are synchronized to the same timeline. That’s essential for cross-correlation, lag analysis, and time-shifting.\n",
    "9. Plotting & Visualization You’ll need DATE_V as the x-axis for any time-series plots. Without it, your arrays are just floating sequences.\n",
    "10. Diagnostics & Gaps You can detect missing data, irregular sampling, or temporal drift by comparing ***\"dtv\"*** across groups.\n",
    "11. Batch Operations If you’re merging arrays from different domains (e.g., Motion, Supplements, Sleep), having a shared **\"dtv\"*** lets you align them cleanly—even if some arrays are sparse.\n",
    ".................array_dict[f\"{group_name}_DATE_V\"] = df.index.to_numpy()\n",
    "---------------------------------------------------------------------\n",
    "{\n",
    "    \"grp_tst_DATE_V\": np.array([...]),\n",
    "    \"grp_tst_Eliquist\": np.array([...]),\n",
    "    \"grp_tst_Magtien\": np.array([...]),\n",
    "    \"grp_tst_GPLC\": np.array([...])\n",
    "}\n",
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d5866-e45b-4f1e-b178-38a0e469e16a",
   "metadata": {},
   "source": [
    "***Let’s scaffold a clean, modular TimeSeriesGroup class that fits your architecture and handles:***\n",
    "\n",
    "✅ Selective column loading from a master CSV\n",
    "\n",
    "✅ Index alignment via DATE_V\n",
    "\n",
    "✅ Dictionary-style access to NumPy arrays\n",
    "\n",
    "✅ Metadata logging for diagnostics and traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96db62-b2a3-443e-8426-c8072118da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesGroup:\n",
    "    def __init__(self, filename: str, group_name: str, columns: list[str], index_col: str = \"DATE_V\", encoding: str = \"ISO-8859-1\"):\n",
    "        self.group_name = group_name\n",
    "        self.index_col = index_col\n",
    "        self.filename = filename\n",
    "        self.encoding = encoding\n",
    "        self.columns = columns\n",
    "        self.array_dict = {}\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        cols_to_load = [self.index_col] + self.columns\n",
    "        df = pd.read_csv(self.filename, usecols=cols_to_load, encoding=self.encoding)\n",
    "        df.set_index(self.index_col, inplace=True)\n",
    "\n",
    "        # Store index as array\n",
    "        self.array_dict[f\"{self.group_name}_{self.index_col}\"] = df.index.to_numpy()\n",
    "\n",
    "        # Store each column as array\n",
    "        for col in self.columns:\n",
    "            arr = df[col].to_numpy()\n",
    "            self.array_dict[f\"{self.group_name}_{col}\"] = arr\n",
    "\n",
    "    def get_array(self, name: str) -> np.ndarray:\n",
    "        return self.array_dict.get(name)\n",
    "\n",
    "    def summary(self):\n",
    "        print(f\"📦 Group: {self.group_name}\")\n",
    "        for key, arr in self.array_dict.items():\n",
    "            print(f\"  {key}: shape={arr.shape}, dtype={arr.dtype}, nulls={np.isnan(arr).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f484d-14e4-41ea-8c53-802182d71661",
   "metadata": {},
   "source": [
    "# Installing an input system to load data manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756607be-3820-4bb5-96c5-24df21899a8a",
   "metadata": {},
   "source": [
    "## *Load the array using* ***safe_csv_read()*** *set index,convert data list to np.arrays & build* ***array_dict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b7c6b-af42-482a-addb-ed8214b29383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the new day and values\n",
    "new_day = \"2025-08-30\"\n",
    "new_values = {\n",
    "    \"Eliquist\": 5.0,\n",
    "    \"Magtien\": 3.2,\n",
    "    \"GPLC\": 1.8\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with dtv as index\n",
    "df_new = pd.DataFrame(new_values, index=[new_day])\n",
    "df_new.index.name = \"dtv\"\n",
    "\n",
    "# Reindex to match master dtv timeline\n",
    "master_dtv = array_dict[\"Motion_dtv\"]\n",
    "df_new = df_new.reindex(master_dtv)\n",
    "\n",
    "# Append each column to array_dict\n",
    "for col in new_values:\n",
    "    array_dict[f\"Motion_{col}\"] = df_new[col].to_numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
