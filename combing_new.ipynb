{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65339162-459e-42b3-a6c4-b1c4bfa0f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106c569-a66b-4fed-a7b7-08aa0af8cd69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create array_dict from an array in a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f65a25-9d74-43c9-87ae-4ac6f5fe03c1",
   "metadata": {},
   "source": [
    "## Read the file with protection from oddball encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47bee77-7048-4736-997f-f76057630da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_csv_read(filename, usecols=None, index_col=None):\n",
    "    ## Read the file with protection from oddball encoders.\n",
    "    try:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(filename, usecols=usecols, index_col=index_col, encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64309361-6a42-4321-a571-30e9b7ae324b",
   "metadata": {},
   "source": [
    "## *Load* ***array_dict*** *using* ***safe_csv_read()*** *set index,convert data list to np.arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c588aa-6125-40e8-b5ae-406242da3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group_arrays(filename: str, group_name: str, grp_list: list[str], index_col: str = \"dtv\") -> dict[str, np.ndarray]:\n",
    "    ## *Load the array using* ***safe_csv_read()*** *set index,convert data list to np.arrays & build* ***array_dict***\n",
    "    \n",
    "    columns_to_load = [index_col] + grp_list\n",
    "    df = safe_csv_read(filename, usecols=columns_to_load)\n",
    "    # before safe_csv_read df = pd.read_csv(filename, usecols=columns_to_load, encoding=encoding)\n",
    "    df.set_index(index_col, inplace=True)\n",
    "\n",
    "    array_dict = {f\"{group_name}_{col}\": df[col].to_numpy() for col in grp_list}\n",
    "    array_dict[f\"{group_name}_{index_col}\"] = df.index.to_numpy()  # include index as array\n",
    "    return array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105af2b-2adb-4cdb-b5e1-04647459ec90",
   "metadata": {},
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05204e34-da7b-4e76-96bc-9e66cd3a31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## *Set* ***filename, group_name, grp_list*** then *call* ***load_group_arrays()*** *to compute np.arrays & build* ***array_dict***\n",
    "filename = \"xl_dtv_all_snm_tst.csv\"\n",
    "group_name = \"grp_tst\"\n",
    "grp_list =[\"Eliquist\",\"Magtien\"]\n",
    "# before group array   array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"DATE_V\", encoding = \"ISO-8859-1\")\n",
    "array_dict = load_group_arrays(filename, group_name , grp_list, index_col = \"dtv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e5a28e-f743-4ac3-87d0-959e42d46a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([10,  9,  8,  7,  6,  5,  4,  3,  2,  1]),\n",
       " 'grp_tst_Magtien': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81fc835-e1f9-4bac-ad22-a8f4baab4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(45854)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict['grp_tst_dtv'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abeb0f3a-e5a7-430b-9fc5-972cc5522be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkout\n",
    "array_dict['grp_tst_Magtien'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f844d6-a1cb-41be-a119-b3b2d1dd5cdf",
   "metadata": {},
   "source": [
    "## *From a ***dtv*** find* ***row_index*** *for a ***specific dtv*** *then use* ***row_index()*** *to find the value in a given dat_col np.array to get the* ***datcol_value*** for that ***specific dtv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6a056a-957d-43c4-b018-747203613e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… row_index for 45852: 3\n"
     ]
    }
   ],
   "source": [
    "# Load the array using safe_csv_read() \n",
    "# set index,convert data list to np.arrays & build array_dict\n",
    "dtv_array = array_dict[\"grp_tst_dtv\"]\n",
    "grp_tst_dtv = 45852\n",
    "\n",
    "# Find the index position\n",
    "row_index = np.where(dtv_array == grp_tst_dtv)[0]\n",
    "\n",
    "if row_index.size > 0:\n",
    "    print(f\"âœ… row_index for {grp_tst_dtv}: {row_index[0]}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Date {grp_tst_dtv} not found in 'grp_tst_dtv'\")\n",
    "# print(\"row_index  =  \",row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc36084-142c-4c00-aa52-b2e0aabafcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict['grp_tst_Magtien'][row_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f484d-14e4-41ea-8c53-802182d71661",
   "metadata": {},
   "source": [
    "# Installing an input system to load data manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ef307-e1f4-434b-8187-aee9d869d7d7",
   "metadata": {},
   "source": [
    "# Manual Input to array_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd134bd-607f-496c-a661-260ae7aeac18",
   "metadata": {},
   "source": [
    "## Interactive Data Entry Function [not addapted from copilot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b268f49a-0bbe-4321-8c5e-4d22405a24cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grp_tst_Eliquist': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       " 'grp_tst_Magtien': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       " 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
       "        45858]),\n",
       " 'grp_tst_GPLC': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       " 'grp_tst_dvt': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8bd7c9c0-dc04-4fb3-b172-91977980390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive Data Entry Function\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "def enter_day_values(array_dict: dict, group_name: str, col_list: list[str], index_key: str = \"dtv\") -> None:\n",
    "    # Prompt for the date\n",
    "    dtv_input = int(input(\"ðŸ“… Enter the date (format: NNNNN): \").strip())\n",
    "    \n",
    "    # Collect values interactively\n",
    "    new_values = {}\n",
    "    for col in col_list:\n",
    "        val = input(f\"ðŸ”¢ Enter value for '{col}': \").strip()\n",
    "        try:\n",
    "            new_values[col] = float(val)\n",
    "        except ValueError:\n",
    "            new_values[col] = np.nan  # fallback if input is invalid\n",
    "    # Create new DataFrame with dtv index\n",
    "    df_new = pd.DataFrame(new_values, index=[dtv_input])\n",
    "    df_new.index.name = index_key\n",
    "    # Reindex to match master timeline\n",
    "    master_index = array_dict.get(f\"{group_name}_{index_key}\")\n",
    "    if master_index is None:\n",
    "        raise KeyError(f\"âŒ Master index '{group_name}_{index_key}' not found in array_dict.\")\n",
    "    df_new = df_new.reindex(master_index)\n",
    "    # Append each column to array_dict\n",
    "    for col in col_list:\n",
    "        key = f\"{group_name}_{col}\"\n",
    "        array_dict[key] = df_new[col].to_numpy()\n",
    "        print(f\"âœ… Updated '{key}' with new entry for {dtv_input}\")\n",
    "    print(array_dict.keys())\n",
    "    print(array_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8f1e9ad-c332-44f8-b910-18f9b7adfe90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ“… Enter the date (format: NNNNN):  45858\n",
      "ðŸ”¢ Enter value for 'Eliquist':  6\n",
      "ðŸ”¢ Enter value for 'Magtien':  6\n",
      "ðŸ”¢ Enter value for 'GPLC':  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated 'grp_tst_Eliquist' with new entry for 45858\n",
      "âœ… Updated 'grp_tst_Magtien' with new entry for 45858\n",
      "âœ… Updated 'grp_tst_GPLC' with new entry for 45858\n",
      "dict_keys(['grp_tst_Eliquist', 'grp_tst_Magtien', 'grp_tst_dtv', 'grp_tst_GPLC', 'grp_tst_dvt'])\n",
      "{'grp_tst_Eliquist': array([nan, nan, nan, nan, nan, nan, nan, nan, nan,  6.]), 'grp_tst_Magtien': array([nan, nan, nan, nan, nan, nan, nan, nan, nan,  6.]), 'grp_tst_dtv': array([45849, 45850, 45851, 45852, 45853, 45854, 45855, 45856, 45857,\n",
      "       45858]), 'grp_tst_GPLC': array([nan, nan, nan, nan, nan, nan, nan, nan, nan,  6.]), 'grp_tst_dvt': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])}\n"
     ]
    }
   ],
   "source": [
    "##### array_dict\n",
    "group_name = \"grp_tst\"\n",
    "col_list = [\"Eliquist\", \"Magtien\", \"GPLC\"]\n",
    "enter_day_values(array_dict, group_name, col_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b7e38-f34c-4391-8e64-a64c9d436345",
   "metadata": {},
   "source": [
    "## 45858 Add a new column [not addapted from copilot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7917a570-58e2-4efe-9976-471e22812c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_aligned_column(array_dict: dict, df_new: pd.DataFrame, col_name: str, group_name: str, index_key: str = \"dtv\") -> None:\n",
    "    # Build the full key name\n",
    "    full_key = f\"{group_name}_{col_name}\"\n",
    "\n",
    "    # Check for name collision\n",
    "    if full_key in array_dict:\n",
    "        raise ValueError(f\"âŒ Column '{full_key}' already exists in array_dict. Choose a unique name or overwrite intentionally.\")\n",
    "\n",
    "    # Get master index\n",
    "    master_index = array_dict.get(f\"{group_name}_{index_key}\")\n",
    "    if master_index is None:\n",
    "        raise KeyError(f\"âŒ Master index '{group_name}_{index_key}' not found in array_dict.\")\n",
    "\n",
    "    # Align new data to master index\n",
    "    new_series = df_new[col_name]\n",
    "    aligned_series = new_series.reindex(master_index)\n",
    "\n",
    "    # Add to array_dict\n",
    "    array_dict[full_key] = aligned_series.to_numpy()\n",
    "    print(f\"âœ… Added '{full_key}' with shape {aligned_series.shape} and {aligned_series.isna().sum()} NaNs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d6e0a-b037-423e-913c-f0dbab7803fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Start of setting up classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be96db62-b2a3-443e-8426-c8072118da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesGroup:\n",
    "    def __init__(self, filename: str, group_name: str, columns: list[str], index_col: str = \"DATE_V\", encoding: str = \"ISO-8859-1\"):\n",
    "        self.group_name = group_name\n",
    "        self.index_col = index_col\n",
    "        self.filename = filename\n",
    "        self.encoding = encoding\n",
    "        self.columns = columns\n",
    "        self.array_dict = {}\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        cols_to_load = [self.index_col] + self.columns\n",
    "        df = pd.read_csv(self.filename, usecols=cols_to_load, encoding=self.encoding)\n",
    "        df.set_index(self.index_col, inplace=True)\n",
    "\n",
    "        # Store index as array\n",
    "        self.array_dict[f\"{self.group_name}_{self.index_col}\"] = df.index.to_numpy()\n",
    "\n",
    "        # Store each column as array\n",
    "        for col in self.columns:\n",
    "            arr = df[col].to_numpy()\n",
    "            self.array_dict[f\"{self.group_name}_{col}\"] = arr\n",
    "\n",
    "    def get_array(self, name: str) -> np.ndarray:\n",
    "        return self.array_dict.get(name)\n",
    "\n",
    "    def summary(self):\n",
    "        print(f\"ðŸ“¦ Group: {self.group_name}\")\n",
    "        for key, arr in self.array_dict.items():\n",
    "            print(f\"  {key}: shape={arr.shape}, dtype={arr.dtype}, nulls={np.isnan(arr).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262970e-f5f5-4730-9a55-2d1262d676b1",
   "metadata": {},
   "source": [
    "# Discriptions of ***array_dict***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965a8b8-122a-4c08-b4de-ed3f6a975cdf",
   "metadata": {},
   "source": [
    "***array_dict*** Is a working dictionary where  dtv is the index and selected dat_cols which are np.arrays\n",
    "1. dtv is a col of integers representing the number of days since jan 1 1900 and ends with today.\n",
    "2. dtv is used as the index for all dat_cols\n",
    "3. all dat_cols have cls attributes common to all the values in that dat-col\n",
    "5. all dat_cols have cls methods that instructions to certain statistics of the dat_col values.\n",
    "6. dat_col attributes and methods are read by a . behind dat_col ie dat_col.method or attribute. ***see*** *https://copilot.microsoft.com/shares/pages/MZyaioewJp2wR4mSwfShP* for examples.\n",
    "7. all have same length as the ***dtv col*** and are stored in a ***xl csv file array*** with ***\"dtv\"*** as the first col and str headers as the first row.\n",
    "8. ***array_dict*** use the ***dtv*** as index so that every row has a ***row_index***\n",
    "9. The ***row_index*** for a ***specific dtv*** is computed and it is used to find the value of ***dat_col*** for that date.  \n",
    "10. ***Time Alignment*** It ensures all arraysâ€”whether supplements, motion, or biochemicalâ€”are synchronized to the same timeline. Thatâ€™s essential for cross-correlation, lag analysis, and time-shifting.\n",
    "11. Plotting & Visualization Youâ€™ll need dtv as the x-axis for any time-series plots. Without it, your arrays are just floating sequences.\n",
    "12. Diagnostics & Gaps You can detect missing data, irregular sampling, or temporal drift by comparing ***\"dtv\"*** across groups.\n",
    "13. Batch Operations If youâ€™re merging arrays from different domains (e.g., Motion, Supplements, Sleep), having a shared **\"dtv\"*** lets you align them cleanlyâ€”even if some arrays are sparse.\n",
    ".................array_dict[f\"{group_name}_dtv] = df.index.to_numpy()\n",
    "---------------------------------------------------------------------\n",
    "{\n",
    "    \"grp_tst_dtv\": np.array([...]),\n",
    "    \"grp_tst_Eliquist\": np.array([...]),\n",
    "    \"grp_tst_Magtien\": np.array([...]),\n",
    "    \"grp_tst_GPLC\": np.array([...])\n",
    "}\n",
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d5866-e45b-4f1e-b178-38a0e469e16a",
   "metadata": {},
   "source": [
    "***Letâ€™s scaffold a clean, modular TimeSeriesGroup class that fits your architecture and handles:***\n",
    "\n",
    "âœ… Selective column loading from a master CSV\n",
    "\n",
    "âœ… Index alignment via DATE_V\n",
    "\n",
    "âœ… Dictionary-style access to NumPy arrays\n",
    "\n",
    "âœ… Metadata logging for diagnostics and traceability"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8b81c9b-6e43-403e-ac6f-5b5800557c20",
   "metadata": {},
   "source": [
    "print(\"bill\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scu)",
   "language": "python",
   "name": "scu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
